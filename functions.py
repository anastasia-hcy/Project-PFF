import os 
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import tensorflow_probability as tfp
tfd = tfp.distributions

#############################################
#  Squared Exponential Kernels & Divergence # 
#############################################

def SE_kernel(x1, x2, scale, length):
    """The Squared Exponential (SE) kernel given two points, x1 and x2, and the two parameters, scale and length."""
    return (scale**2) * tf.math.exp( - (x1-x2)**2 / (2*length) ) 


def SE_kernel_divC(x1, x2, length):
    """Compute and return the constant part of the derivative of Squared Exponential (SE) kernel given two points, x1 and x2, and the length parameter."""
    return - (x1-x2) / length


def SE_Cov_div(ndims, x, scale=None, length=None):
    """
    Compute the covariance matrix and the constant part of its derivatives using the Squared Exponential (SE) kernel given a vector, x

    Keyword args:
    -------------
    ndims : int32. Dimension of input vector, x. 
    x : tf.Tensor/array/list of float64. Input vector x to be evaluated. 
    scale : float64, optional. The scale parameter for the SE kernel. Defaults to 1.0 if not provided.
    length : float64, optional. The length parameter for the SE kernel. Defaults to 1.0 if not provided.

    Returns:
    --------
    M : tf.Variable of float64 with shape (ndims,ndims). The covariance matrix. 
    Md : tf.Variable of float64 with shape (ndims,ndims). The constant part of the derivatives of the covariance matrix.
    """
    scale           = 1.0 if scale is None else scale 
    length          = 1.0 if length is None else length 

    M               = tf.Variable( tf.zeros((ndims,ndims), dtype=tf.float64) )
    Md              = tf.Variable( tf.zeros((ndims,ndims), dtype=tf.float64) )

    for i in range(ndims): 
        for j in range(i,ndims): 

            v       = SE_kernel(x[i], x[j], scale=scale, length=length)
            M[i,j].assign(v)                     
            M[j,i].assign(v)                     

            vd      = SE_kernel_divC(x[i], x[j], length=length)
            Md[i,j].assign(vd)
            Md[j,i].assign(-vd)

    return M, Md



##############################
#  Gaussian random variables # 
############################## 


def norm_rvs(n, mean, Sigma):
    """
    Generate Gaussian random variables using Cholesky decomposition and standard Normal given the expectation and covariance matrix, mean and Sigma.

    Keyword args:
    -------------
    n : int32. Dimension of input expectation vector, mean. 
    mean : tf.Tensor/array/list of float64 with shape (n,). Expectation of the Gaussian random variables to be generated. 
    Sigma : tf.Tensor/array of float64 with shape (n,n). Covariance of the Gaussian random variables to be generated. 

    Returns:
    --------
    x : tf.Tensor of float64 with shape (n,). A Gaussian random vector. 
    """
    chol            = tf.linalg.cholesky(Sigma)
    x_par           = tf.random.normal((n,), dtype=tf.float64)
    x               = tf.linalg.matvec(chol, x_par) + mean
    return x



######################################
#  Linear Gaussian State Space Model # 
######################################


def LGSSM(nTimes, ndims, A=None, B=None, V=None, W=None, mu0=None, Sigma0=None):
    """
    Generate random variables from a linear Gaussian state space model (SSM) for the given time and state dimensions, nTimes and ndims.

    Keyword args:
    -------------
    nTimes : int32. Dimension of discrete time step of SSM.
    ndims : int32. Dimension of state space. 
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to identity matrix if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims), optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optional. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims), optional. The prior covariance for initial state. Defaults to identity matrix if not provided.

    Returns:
    --------
    X : tf.Variable of float64 with dimension (nTimes,ndims). The states generated by the linear Gaussian SSM.
    Y : tf.Variable of float64 with dimension (nTimes,ndims). The measurements generated by the linear Gaussian SSM.
    """
    A               = tf.eye(ndims, dtype=tf.float64) if A is None else A
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W
    
    mu0             = tf.zeros((ndims,), dtype=tf.float64) if mu0 is None else mu0
    Sigma0          = tf.eye(ndims, dtype=tf.float64) if Sigma0 is None else Sigma0
    
    x0              = norm_rvs(ndims, mu0, Sigma0)
    y0              = norm_rvs(ndims, x0, W)
    
    X               = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    Y               = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    
    X[0,:].assign(x0)    
    Y[0,:].assign(y0)
    for i in tf.range(1, nTimes):
        xi          = norm_rvs(ndims, tf.linalg.matvec(A, X[i-1,:]), V)  
        yi          = norm_rvs(ndims, tf.linalg.matvec(B, xi), W)      
        X[i,:].assign(xi)
        Y[i,:].assign(yi)
        
    return X, Y



###############################
# Stochastic Volatility Model # 
###############################

def SV_transform(n, m, B, x, W, U=None):
    """Generate and return the measurements of the stochastic volatility model given the latent system states, x."""
    U               = tf.zeros((n,n), dtype=tf.float64) if U is None else U
    z               = tf.linalg.matvec(B, tf.math.exp(x/2))     
    C               = tf.linalg.diag(z) @ W @ tf.linalg.diag(z) 
    y               = norm_rvs(n, m, C+U)
    y2              = tf.where( tf.math.is_nan(y) , tf.cast(0.0, tf.float64), y)   
    return y2


def SVSSM(nTimes, ndims, A=None, B=None, V=None, W=None, mu0=None, Sigma0=None, muy=None, n_sparse=None):
    """
    Generate random variables from a linear Gaussian state space model (SSM) for the given time and state dimensions, nTimes and ndims.

    Keyword args:
    -------------
    nTimes : int32. Dimension of discrete time step of SSM.
    ndims : int32. Dimension of state space. 
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims). The prior covariance for initial state. Defaults to predefined covariance using V and A if not provided.
    muy : tf.Tensor of float64 with shape (ndims,), optioanl. The expectation of the measurements. Defaults to zeros if not provided.

    Returns:
    --------
    X : tf.Variable of float64 with dimension (nTimes,ndims). The states generated by the linear Gaussian SSM.
    Y : tf.Variable of float64 with dimension (nTimes,ndims). The measurements generated by the linear Gaussian SSM.
    """
    
    n_sparse        = ndims if n_sparse is None else n_sparse
    
    A               = tf.eye(ndims, dtype=tf.float64) * 0.5 if A is None else A
    if A is not None and tf.reduce_max(A) > 1.0:
        raise ValueError("The matrix A out of range [-1,1].")
    if A is not None and tf.reduce_min(A) < -1.0:
        raise ValueError("The matrix A out of range [-1,1].")
        
    B               = tf.ones((n_sparse, ndims), dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V 
    W               = tf.eye(n_sparse, dtype=tf.float64) if W is None else W
    
    mu0             = tf.zeros((ndims,), dtype=tf.float64) if mu0 is None else mu0
    Sigma0          = (V @ V) @ tf.linalg.inv(tf.eye(ndims, dtype=tf.float64) - A @ A) if Sigma0 is None else Sigma0
    muy             = tf.zeros((n_sparse,), dtype=tf.float64) if muy is None else muy
    
    x0              = norm_rvs(ndims, mu0, Sigma0)
    y0              = SV_transform(n_sparse, muy, B, x0, W)

    X               = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    Y               = tf.Variable(tf.zeros((nTimes, n_sparse), dtype=tf.float64))

    X[0,:].assign(x0)    
    Y[0,:].assign(y0)
    for i in range(1, nTimes):
        xi          = norm_rvs(ndims, tf.linalg.matvec(A, X[i-1,:]), V)
        yi          = SV_transform(n_sparse, muy, B, xi, W)     
        X[i,:].assign(xi)
        Y[i,:].assign(yi)

    return X, Y

##########################
# Standard Kalman Filter # 
##########################

def KF_Predict(x_prev, P_prev, A, V):
    "Predict and return the system state and covariance matrix, x and P, given the previous, x_prev and P_prev."
    x               = tf.linalg.matvec(A, x_prev)
    P               = A @ P_prev @ tf.transpose(A) + V
    return x, P 

def KF_Gain(P, B, W):
    "Compute and return the standard Kalman gain."
    M               = P @ tf.transpose(B) 
    Minv            = tf.linalg.inv(B @ M + W) 
    return M @ Minv

def KF_Filter(x_prev, P_prev, y_obs, y_prev, B, K):
    "Filter the predicted system state and covariance matrix, x_prev and P_prev, using the Kalman gain and observed measurments, K and y_obs."
    x               = x_prev + tf.linalg.matvec(K, y_obs - y_prev)
    P               = P_prev - P_prev @ tf.transpose(B) @ tf.transpose(K)
    return x, P

def KalmanFilter(y, A=None, B=None, V=None, W=None, mu0=None, Sigma0=None):
    """
    Compute the estimated states using the standard Kalman Filter given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The measurements generated by LGSSM. 
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to identity matrix if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims), optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optional. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims), optional. The prior covariance for initial state. Defaults to identity matrix if not provided.

    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the standard Kalman Filter. 
    """
    nTimes, ndims   = y.shape 
    mu0             = tf.zeros((ndims,), dtype=tf.float64) if mu0 is None else mu0
    Sigma0          = tf.eye(ndims, dtype=tf.float64) if Sigma0 is None else Sigma0
    A               = tf.eye(ndims, dtype=tf.float64) if A is None else A
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W
    
    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    x_prev          = norm_rvs(ndims, mu0, Sigma0) 
    P_prev          = A @ Sigma0 @ tf.transpose(A) + V

    for i in range(nTimes):
        x_pred, P_pred     = KF_Predict(x_prev, P_prev, A, V)
        K                  = KF_Gain(P_pred, B, W)
        y_pred             = tf.linalg.matvec(B, x_pred)
        x_filt, P_filt     = KF_Filter(x_pred, P_pred, y[i,:], y_pred, B, K)
        x_prev, P_prev     = x_filt, P_filt        
        X_filtered[i,:].assign(x_prev)  
        
    return X_filtered


##########################
# Extended Kalman Filter # 
##########################


def EKF_Predict(x_prev, P_prev, A, V):
    """Predict and return the system state and covariance matrix, x and P, given the previous, x_prev and P_prev."""
    x               = tf.linalg.matvec(A, x_prev)
    P               = A @ P_prev @ tf.transpose(A) + V
    return x, P 

def EKF_Jacobi(x, y, B):
    """Compute and return the pseudo-estimate Jacobian matrices for the stochastic volatility model."""

    Jx              = tf.linalg.diag(y/2)
    Jx2             = tf.where( tf.math.logical_and(tf.math.is_inf(Jx), Jx > 0.0) , tf.cast(1e9, tf.float64), Jx)
    Jx2             = tf.where( tf.math.logical_and(tf.math.is_inf(Jx), Jx < 0.0) , tf.cast(-1e9, tf.float64), Jx2)
    Jx2             = tf.where( tf.math.is_nan(Jx) , tf.cast(0.0, tf.float64), Jx2)
    
    Jw              = tf.linalg.diag(tf.linalg.matvec(B, tf.math.exp(x/2)))
    Jw2             = tf.where( tf.math.logical_and(tf.math.is_inf(Jw), Jw > 0.0) , tf.cast(1e9, tf.float64), Jw)
    Jw2             = tf.where( tf.math.logical_and(tf.math.is_inf(Jw), Jw < 0.0) , tf.cast(-1e9, tf.float64), Jw2)
    Jw2             = tf.where( tf.math.is_nan(Jw) , tf.cast(0.0, tf.float64), Jw2)
    
    return Jx, Jw2

def EKF_Gain(P, Jx, Jw, W, U):
    """Compute and return the Extended Kalman gain."""
    Mx              = P @ tf.transpose(Jx)
    J               = Jx @ Mx + Jw @ W @ tf.transpose(Jw)
    Minv            = tf.linalg.inv(J + U) 
    return Mx @ Minv

def EKF_Filter(x_prev, P_prev, y_obs, y_prev, Jx, K):
    """Filter the predicted system state and covariance matrix, x_prev and P_prev, using the Kalman gain and observed measurments, K and y_obs."""
    x               = x_prev + tf.linalg.matvec(K, y_obs - y_prev)
    P               = P_prev - P_prev @ tf.transpose(Jx) @ tf.transpose(K) 
    return x, P

def ExtendedKalmanFilter(y, A=None, B=None, V=None, W=None, mu0=None, Sigma0=None, muy=None):
    """
    Compute the estimated states using the Extended Kalman Filter given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The measurements generated by SVSSM. 
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims). The prior covariance for initial state. Defaults to predefined covariance using V and A if not provided.
    muy : tf.Tensor of float64 with shape (ndims,), optioanl. The expectation of the measurements. Defaults to zeros if not provided.

    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the Extended Kalman Filter. 
    """
    nTimes, ndims   = y.shape 
    
    A               = tf.eye(ndims, dtype=tf.float64) * 0.5 if A is None else A
    if A is not None and tf.reduce_max(A) >= 1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    if A is not None and tf.reduce_min(A) <= -1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W
    
    mu0             = tf.zeros((ndims,), dtype=tf.float64) if mu0 is None else mu0
    Sigma0          = (V @ V) @ tf.linalg.inv(tf.eye(ndims, dtype=tf.float64) - A @ A) if Sigma0 is None else Sigma0
    muy             = tf.zeros((ndims,), dtype=tf.float64) if muy is None else muy
    u               = tf.eye(ndims, dtype=tf.float64) * 1e-9

    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))

    x_prev          = norm_rvs(ndims, mu0, Sigma0) 
    P_prev          = A @ Sigma0 @ tf.transpose(A) + V
    
    for i in range(nTimes):
        x_pred, P_pred              = EKF_Predict(x_prev, P_prev, A, V)
        y_pred                      = SV_transform(ndims, muy, B, x_pred, W, u)
        Jx, Jw                      = EKF_Jacobi(x_pred, y_pred, B)
        K                           = EKF_Gain(P_pred, Jx, Jw, W, u)
        x_filt, P_filt              = EKF_Filter(x_pred, P_pred, y[i,:], y_pred, Jx, K)
        x_prev, P_prev              = x_filt, P_filt        
        X_filtered[i,:].assign(x_prev) 
        
    return X_filtered


###########################
# Unscented Kalman Filter # 
###########################

def SigmaWeights(ndims, alpha=None, kappa=None, beta=None):
    """Compute and return the weights of sigma-points."""
    alpha           = 1.0 if alpha is None else alpha
    kappa           = 3.0 * ndims / 2.0 if kappa is None else kappa
    beta            = 2.0 if beta is None else beta
    Lambda          = (alpha**2) * kappa
    w0m             = (Lambda - ndims) / Lambda 
    w0c             = w0m + (1 - alpha**2 + beta)
    wi              = 1 / (2*Lambda)
    return w0m, w0c, wi, Lambda

def SigmaPoints(ndims, xhat, Phat, Lambda):  
    """Compute and return a set of 2 * ndims + 1 sigma-points."""
    sqrtMat         = tf.linalg.sqrtm(Lambda * Phat)
    SP              = tf.Variable(tf.zeros((2*ndims+1, ndims), dtype=tf.float64))
    SP[0,:].assign(xhat)
    for i in range(1, ndims):
        SP[i,:].assign( xhat + sqrtMat[:,i] )
        SP[ndims+i,:].assign( xhat - sqrtMat[:,i] ) 
    return SP

def UKF_Predict_mean(weight0m, weighti, SP):
    """Compute and return the estimated mean of the transformed variables."""
    return weight0m * SP[0,:] + tf.reduce_sum( weighti * SP[1:,:], axis=0 )

def UKF_Predict_cov(ndims, weight0c, weighti, SP, mean, u, Cov=None):
    """Compute and return the estimated covariance of the transformed variables."""
    Cov             = tf.zeros((ndims,ndims), dtype=tf.float64) if Cov is None else Cov 
    diffs           = SP - mean 
    cov1            = weight0c * tf.tensordot(diffs[0,:], diffs[0,:], axes=0)
    for i in range(1, ndims):
        cov1        += weighti * tf.tensordot(diffs[i,:], diffs[i,:], axes=0)
    return cov1 + Cov + u
    
def UKF_Predict_crosscov(ndims, weight0c, weighti, SP, mean, SP2, mean2, u):
    """Compute and return the estimated cross-covariance of the transformed variables."""
    diffs           = SP - mean
    diffs2          = SP2 - mean2
    cov             = weight0c * tf.tensordot(diffs[0,:], diffs2[0,:], axes=0)
    for i in range(1, ndims):       
        cov         += weighti * tf.tensordot(diffs[i,:], diffs2[i,:], axes=0)
    return cov + u

def UKF_Gain(Cn, Wn, u):
    """Compute and return the unscented Kalman gain."""
    M           =  tf.linalg.inv(Wn + u)
    return Cn @ M

def UKF_Filter(x1, P1, Wn, y_obs, y_pred, K):
    """Filter the predicted system state and covariance matrix, x1 and P1, using the Kalman gain and observed measurments, K and y_obs."""
    x               = x1 + tf.linalg.matvec(K, y_obs - y_pred)
    P               = P1 - K @ Wn @ tf.transpose(K)
    return x, P

def UnscentedKalmanFilter(y, A=None, B=None, V=None, W=None, mu0=None, Sigma0=None):
    """
    Compute the estimated states using the Unscented Kalman Filter given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The measurements generated by SVSSM. 
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims). The prior covariance for initial state. Defaults to predefined covariance using V and A if not provided.
    
    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the Unscented Kalman Filter. 
    """
    nTimes, ndims   = y.shape 
    
    A               = tf.eye(ndims, dtype=tf.float64) * 0.5 if A is None else A
    if A is not None and tf.reduce_max(A) >= 1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    if A is not None and tf.reduce_min(A) <= -1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W
    
    mu0             = tf.zeros((ndims,), dtype=tf.float64) if mu0 is None else mu0
    Sigma0          = (V @ V) @ tf.linalg.inv(tf.eye(ndims, dtype=tf.float64) - A @ A) if Sigma0 is None else Sigma0

    u               = tf.eye(ndims, dtype=tf.float64) * 1e-9
    
    weight0_m, weight0_c, weighti, L = SigmaWeights(ndims) 

    x_pred0         = tf.Variable(tf.zeros((ndims*2,), dtype=tf.float64))
    P_pred0         = tf.Variable(tf.zeros((ndims*2,ndims*2), dtype=tf.float64))
    P_pred0[ndims:ndims*2,ndims:ndims*2].assign(W) 
        
    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    
    x_prev          = norm_rvs(ndims, mu0, Sigma0) 
    P_prev          = A @ Sigma0 @ tf.transpose(A) + V

    for i in range(nTimes):

        Xprev_sp    = SigmaPoints(ndims, x_prev, P_prev, L)
        X_sp        = Xprev_sp @ tf.transpose(A) 

        x_pred      = UKF_Predict_mean(weight0_m, weighti, X_sp) 
        P_pred      = UKF_Predict_cov(ndims, weight0_c, weighti, X_sp, x_pred, u, Cov=V)  
        
        x_pred0[:ndims].assign(x_pred)
        P_pred0[0:ndims,0:ndims].assign(P_pred)
        
        Xpred_sp    = SigmaPoints(ndims*2, x_pred0, P_pred0, L)
        Y_sp        = tf.math.exp(Xpred_sp[:,:ndims]/2) @ tf.transpose(B) * Xpred_sp[:,ndims:]
        
        y_pred      = UKF_Predict_mean(weight0_m, weighti, Y_sp)
        W_pred      = UKF_Predict_cov(ndims, weight0_c, weighti, Y_sp, y_pred, u)
        
        C_pred      = UKF_Predict_crosscov(ndims, weight0_c, weighti, Xpred_sp[:,:ndims], x_pred, Y_sp, y_pred, u) 
        K           = UKF_Gain(C_pred, W_pred, u)
            
        x_filt, P_filt      = UKF_Filter(x_pred, P_pred, W_pred, y[i,:], y_pred, K)
        x_prev, P_prev      = x_filt, P_filt        
        X_filtered[i,:].assign(x_prev) 
        
    return X_filtered



#################################
# Functions for Particle Filter # 
#################################


def initiate_particles(N, n, mu0, Sigma0):
    """Draw and return a set of initial particles from the importance distribution."""
    x0              = tf.Variable(tf.zeros((N,n), dtype=tf.float64)) 
    for i in range(N):  
        x0[i,:].assign( norm_rvs(n, mu0, Sigma0) )
    return x0 

def LogImportance(x, mu0, Sigma0):
    """Compute and return the log probability of the state vector, x, using the importance distribution given the mean, mu0, and the covariance, Sigma0."""
    InvSigma0       = tf.linalg.inv(Sigma0)
    diff            = x - mu0
    return - 1/2 * tf.math.log(tf.linalg.det(Sigma0)) - 1/2 * tf.linalg.tensordot( tf.linalg.matvec(InvSigma0, diff), diff, axes=1) 

def LogLikelihood(x, y, muy, Sigma, U):
    """Compute and return the log likelihood of the measurements of the stochastic volatility model, y, given the measurement mean, muy, and the covariance, Sigma. """
    xe              = tf.math.exp(x/2)
    Ci              = tf.linalg.diag(xe) @ Sigma @ tf.linalg.diag(xe) + U 
    
    InvCi           = tf.linalg.inv(Ci)
    detCi           = tf.linalg.det(Ci)
    return - 1/2 * tf.math.log(detCi) - 1/2 * tf.linalg.tensordot( tf.linalg.matvec(InvCi, (y - muy)), (y - muy), axes=1) 

def LogTarget(x, xprev, Sigma0):
    """Compute and return the log probability of the state vector, x, using the target distribution given the previous state, xprev, and the covariance, Sigma0."""
    InvSigma0       = tf.linalg.inv(Sigma0)
    diff            = x - xprev
    return - 1/2 *  tf.math.log(tf.linalg.det(Sigma0)) - 1/2 * tf.linalg.tensordot( tf.linalg.matvec(InvSigma0, diff), diff, axes=1) 


def draw_particles(N, n, y, xprev, SigmaX, muy, SigmaY, Sigma0, U):
    """Draw particles, xn, from the importance distribution and compute the log posterior probability, Lp."""
    xn              = tf.Variable(tf.zeros((N,n), dtype=tf.float64)) 
    Lp              = tf.Variable(tf.zeros((N,), dtype=tf.float64)) 
    for i in range(N):  
        xi          = norm_rvs(n, xprev[i,:], Sigma0)
        xn[i,:].assign(xi)
        Lp[i].assign( LogLikelihood(xi, y, muy, SigmaY, U) + LogTarget(xi, xprev[i,:], SigmaX) - LogImportance(xi, xprev[i,:], Sigma0) )      
    return xn, Lp 

def compute_weights(w0, Lp):
    """Compute and return the importance weights using the previous weights, w0, and the log posterior probability, Lp."""
    return tf.math.exp( tf.math.log(w0) + Lp )

def normalize_weights(w):
    """Normalize the weights, w, and return the normalized weights that sum up to one."""
    return w / tf.reduce_sum(w)

def compute_ESS(w):
    """Compute and return the effective sample size using the normalized weights, w."""
    return 1 / tf.reduce_sum(w**2)

def multinomial_resample(N, x, w):
    """Resample from the set of particles, x, using the weights, w, as multinomial probabilities and return the new set of particles, xbar, and the new weights, wbar."""
    dist            = tfd.Categorical(probs=w)
    indices         = dist.sample(N)
    xbar            = tf.gather(x, indices)
    wbar            = tf.ones((N,), dtype=tf.float64) / N 
    return xbar, wbar 

def compute_posterior(w, x):
    "Compute and return the posterior estimates of the state using the weights, w, and the particles, x. "
    return tf.linalg.matvec( tf.transpose(x), w ) 



############################
# Standard Particle Filter # 
############################


def ParticleFilter(y, A=None, B=None, V=None, W=None, N=None, resample=None, mu0=None, Sigma0=None, muy=None):
    """
    Compute the estimated states using the standard Particle Filter given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The measurements generated by SVSSM. 
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    N : int32, optional. Defaults to 1000 if not provided.
    resample : Bool, optional. Defaults to True if not provided. 
    mu0 : tf.Tensor of float64 with shape (ndims,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims). The prior covariance for initial state. Defaults to predefined covariance using V and A if not provided.
    muy : tf.Tensor of float64 with shape (ndims,), optioanl. The expectation of the measurements. Defaults to zeros if not provided.

    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the standard Particle Filter. 
    ESS : tf.Variable of float64 with dimension (nTimes,). The effective sample sizes before resampling. 
    Weights : tf.Variable of float64 with dimension (nTimes,N). The normalized weights of particles before resampling.
    X_part : tf.Variable of float64 with dimension (nTimes,N,ndims). The particles before resampling.
    X_part2 : tf.Variable of float64 with dimension (nTimes,N,ndims). THe particles after resampling.
    """
    
    nTimes, ndims   = y.shape 

    A               = tf.eye(ndims, dtype=tf.float64) * 0.5 if A is None else A
    if A is not None and tf.reduce_max(A) >= 1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    if A is not None and tf.reduce_min(A) <= -1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W

    mu0             = tf.zeros((ndims,), dtype=tf.float64) if mu0 is None else mu0
    Sigma0          = (V @ V) @ tf.linalg.inv(tf.eye(ndims, dtype=tf.float64) - A @ A) if Sigma0 is None else Sigma0
    muy             = tf.zeros((ndims,), dtype=tf.float64) if muy is None else muy

    N               = 1000 if N is None else N
    resample        = True if resample is None else resample
    NT              = N/2
    u               = tf.eye(ndims, dtype=tf.float64) * 1e-9

    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    ESS             = tf.Variable(tf.zeros((nTimes,), dtype=tf.float64))
    Weights         = tf.Variable(tf.zeros((nTimes,N), dtype=tf.float64))
    X_part          = tf.Variable(tf.zeros((nTimes,N,ndims), dtype=tf.float64))
    X_part2         = tf.Variable(tf.zeros((nTimes,N,ndims), dtype=tf.float64))
    
    x_prev          = initiate_particles(N, ndims, mu0, Sigma0)
    w_prev          = tf.Variable(tf.ones((N,), dtype=tf.float64) / N) 

    for i in range(nTimes):
        
        x_pred, lp  = draw_particles(N, ndims, y[i,:], x_prev, V, muy, W, Sigma0, u)

        w_pred      = compute_weights(w_prev, lp)
        w_norm      = normalize_weights(w_pred) 
        
        Weights[i,:].assign(w_norm)
        X_part[i,:,:].assign(x_pred)
        
        ness        = compute_ESS(w_norm)
        ESS[i].assign(ness)
        
        if resample == True and ness < NT: 
            xbar, wbar  = multinomial_resample(N, x_pred, w_norm)
            x_filt      = compute_posterior(wbar, xbar)
            x_prev      = xbar
        else: 
            x_filt      = compute_posterior(w_norm, x_pred)
            x_prev      = x_pred

        X_part2[i,:,:].assign(x_prev)
        X_filtered[i,:].assign(x_filt)

    return X_filtered, ESS, Weights, X_part, X_part2 



##############################
# Particle Flow Filter - EDH # 
##############################


def Li17eq10(L, H, P, R, U):
    """Compute and return the first component, A, of the particle flow dynamics, Ax + b, under the assumption of linear Gaussian."""
    C               = tf.linalg.inv( L * H @ P @ tf.transpose(H) + R + U )
    return -1/2 * P @ tf.transpose(H) @ C @ H 

def Li17eq11(I, L, A, H, P, R, y, ei, e0i, U):
    """Compute and return the second component, b, of the particle flow dynamics, Ax + b, under the assumption of linear Gaussian."""
    M1          = (I + 2*L * A) 
    M2          = (I + L * A) @ P @ tf.transpose(H) @ tf.linalg.inv(R + U)
    v           = tf.linalg.matvec(M2, (y - ei)) + tf.linalg.matvec(A, e0i)
    return tf.linalg.matvec(M1, v)


def EDH_linearize_EKF(N, n, xprev, xhat, Pprev, A, V, U): 
    """Predict the pseudo particles, eta and eta0, by EKF using the previous state and its associated particles, xhat, xprev."""
    m_pred, P_pred  = EKF_Predict(xhat, Pprev, A, V) 
    eta             = tf.Variable(m_pred)
    eta0            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    for i in range(N):
        eta0[i,:].assign( norm_rvs(n, xprev[i,:], P_pred + U) )    
    return eta, eta0, m_pred, P_pred 


def EDH_linearize_UKF(N, n, xprev, xhat, Pprev, A, V, wm, wc, wi, L, U):
    """Predict the pseudo particles, eta and eta0, by UKF using the previous state and its associated particles, xhat and xprev."""
        
    Xprev_sp        = SigmaPoints(n, xhat, Pprev, L)
    X_sp            = Xprev_sp @ tf.transpose(A) 
    
    m_pred          = UKF_Predict_mean(wm, wi, X_sp) 
    P_pred          = UKF_Predict_cov(n, wc, wi, X_sp, m_pred, U, Cov=V)  
    
    eta             = tf.Variable(m_pred) 
    eta0            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    for i in range(N): 
        eta0[i,:].assign( norm_rvs(n, xprev[i,:], P_pred + U) )   
        
    return eta, eta0, m_pred, P_pred 


def EDH_flow_dynamics(N, n, Lamb, epsilon, I, e, e0, P, H, R, er, y, U):
    """Compute and return the flow dynamics of the pseudo particles for migration."""
    Ai              = Li17eq10(Lamb, H, P, R, U)
    bi              = Li17eq11(I, Lamb, Ai, H, P, R, y, er, e, U)
    move0           = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    for i in range(N): 
        move0[i,:].assign( epsilon * (tf.linalg.matvec(Ai, e0[i,:]) + bi) )  
    move            = epsilon * (tf.linalg.matvec(Ai, e) + bi) 
    return move0, move

def EDH_flow_lp(N, eta0, eta1, xprev, y, SigmaX, muy, SigmaY, U):
    """Compute and return the log posterior of the migrated pseudo particles."""
    Lp              = tf.Variable(tf.zeros((N,), dtype=tf.float64)) 
    for i in range(N):  
        Lp[i].assign( LogLikelihood(eta1[i,:], y, muy, SigmaY, U) + LogTarget(eta1[i,:], xprev[i,:], SigmaX) - LogImportance(eta0[i,:], xprev[i,:], SigmaX) )  
    return Lp



def EDH(y, A=None, B=None, V=None, W=None, N=None, mu0=None, Sigma0=None, muy=None, method=None, stepsize=None):
    """
    Compute the estimated states using the EDH given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The measurements generated by SVSSM. 
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    N : int32, optional. Defaults to 1000 if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims). The prior covariance for initial state. Defaults to predefined covariance using V and A if not provided.
    muy : tf.Tensor of float64 with shape (ndims,), optioanl. The expectation of the measurements. Defaults to zeros if not provided.
    method : str, optional. The linearization method. Defaults to "UKF" if not provided.  
    stepsize : float64, optional. The stepsize in the psuedo time interval [0,1]. Defaults to 1e-3 if not provided. 
    
    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the EDH.
    ESS : tf.Variable of float64 with dimension (nTimes,). The effective sample sizes before resampling. 
    Weights : tf.Variable of float64 with dimension (nTimes,N). The weights of the particles before resampling. 
    JacobiX : tf.Variable of float64 with dimension (nTimes,ndims,ndims). The pseudo Jacobian matrix with respect to the state. 
    JacobiW : tf.Variable of float64 with dimension (nTimes,ndims,ndims). The pseudo Jacobian matrix with respect to the noise. 
    """
    
    nTimes, ndims   = y.shape 

    A               = tf.eye(ndims, dtype=tf.float64) * 0.5 if A is None else A
    if A is not None and tf.reduce_max(A) >= 1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    if A is not None and tf.reduce_min(A) <= -1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W

    mu0             = tf.zeros((ndims,), dtype=tf.float64) if mu0 is None else mu0
    Sigma0          = (V @ V) @ tf.linalg.inv(tf.eye(ndims, dtype=tf.float64) - A @ A) if Sigma0 is None else Sigma0
    muy             = tf.zeros((ndims,), dtype=tf.float64) if muy is None else muy

    N               = 1000 if N is None else N
    Np              = N
    NT              = N/2
    
    method          = "UKF" if method is None else method 
    weight0_m, weight0_c, weighti, L = SigmaWeights(ndims)
    
    stepsize        = 1e-3 if stepsize is None else stepsize     
    Nl              = 30
    Rates           = [stepsize] + [stepsize * (1.2*i) for i in range(1,30)]
    
    u               = tf.eye(ndims, dtype=tf.float64) * 1e-9
    I               = tf.eye(ndims, dtype=tf.float64)

    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    ESS             = tf.Variable(tf.zeros((nTimes,), dtype=tf.float64))
    Weights         = tf.Variable(tf.zeros((nTimes, Np), dtype=tf.float64))
    
    Jacobi_X        = tf.Variable(tf.zeros((nTimes,ndims,ndims), dtype=tf.float64))
    Jacobi_W        = tf.Variable(tf.zeros((nTimes,ndims,ndims), dtype=tf.float64))
    
    x_filt          = tf.Variable(mu0, dtype=tf.float64)
    P_prev          = A @ Sigma0 @ tf.transpose(A) + V 
    x_prev          = initiate_particles(Np, ndims, x_filt, P_prev)
    w_prev          = tf.Variable(tf.ones((N,), dtype=tf.float64) / N) 

    for i in range(nTimes): 

        if method == "UKF":        
            eta, eta0, m_pred, P_pred   = EDH_linearize_UKF(Np, ndims, x_prev, x_filt, P_prev, A, V, weight0_m, weight0_c, weighti, L, u)

            x_pred0                     = tf.Variable(tf.zeros((ndims*2,), dtype=tf.float64))
            P_pred0                     = tf.Variable(tf.zeros((ndims*2,ndims*2), dtype=tf.float64))

            x_pred0[:ndims].assign(m_pred)
            P_pred0[ndims:ndims*2,ndims:ndims*2].assign(W)     
            P_pred0[0:ndims,0:ndims].assign(P_pred)
            
            xsp                         = SigmaPoints(ndims*2, x_pred0, P_pred0, L)
            ysp                         = tf.math.exp(xsp[:,:ndims]/2) @ tf.transpose(B) * xsp[:,ndims:]
            
            y_pred                      = UKF_Predict_mean(weight0_m, weighti, ysp)
            R                           = UKF_Predict_cov(ndims, weight0_c, weighti, ysp, y_pred, u)
            H, Hw                       = EKF_Jacobi(m_pred, y_pred, B)
            el                          = y_pred - tf.linalg.matvec(H, m_pred) 
            

        if method == "EKF":            
            eta, eta0, m_pred, P_pred   = EDH_linearize_EKF(Np, ndims, x_prev, x_filt, P_prev, A, V, u)
            y_pred                      = SV_transform(ndims, muy, B, m_pred, W, u) 
            H, Hw                       = EKF_Jacobi(m_pred, y_pred, B)
            R                           = Hw @ W @ tf.transpose(Hw)
            el                          = y_pred - tf.linalg.matvec(H, m_pred) 
            
        Jacobi_X[i,:,:].assign( H )
        Jacobi_W[i,:,:].assign( Hw )

        eta1        = eta0
        Lamb        = 0.0
        for j in range(Nl): 
            eta1_move, eta_move         = EDH_flow_dynamics(Np, ndims, Lamb, Rates[j], I, eta, eta1, P_pred, H, R, el, y[i,:], u)  
            Lamb += Rates[j]
            eta.assign_add(eta_move)
            eta1.assign_add(eta1_move)
            
        lp                              = EDH_flow_lp(Np, eta0, eta1, x_prev, y[i,:], P_pred, muy, W, u)     
        
        w_pred                          = compute_weights(w_prev, lp)
        w_norm                          = normalize_weights(w_pred)        
        ness                            = compute_ESS(w_norm)
        ESS[i].assign(ness)
        Weights[i,:].assign(w_norm)   
             
        if ness < NT: 
            xbar, wbar  = multinomial_resample(Np, eta1, w_norm)
            x_filt      = compute_posterior(wbar, xbar)
            x_prev      = xbar
        else: 
            x_filt      = compute_posterior(w_norm, eta1)
            x_prev      = eta1
        
        X_filtered[i,:].assign(x_filt) 
        
        if method == "UKF":
            C_pred                      = UKF_Predict_crosscov(ndims, weight0_c, weighti, xsp[:,:ndims], m_pred, ysp, y_pred, u) 
            K                           = UKF_Gain(C_pred, R, u)
            _, P_filt                   = UKF_Filter(m_pred, P_pred, R, y[i,:], y_pred, K)

        if method == "EKF":    
            K                           = EKF_Gain(P_pred, H, Hw, W, u)
            _, P_filt                   = EKF_Filter(m_pred, P_pred, y[i,:], y_pred, H, K)

        P_prev      = P_filt
        
    return X_filtered, ESS, Weights, Jacobi_X, Jacobi_W







##############################
# Particle Flow Filter - LEDH # 
##############################



def LEDH_linearize_EKF(N, n, xprev, Pprev, A, B, V, W, muy, U): 
    """Predict the pseudo particles, eta and eta0, by EKF using the previous state and its associated particles, xhat and xprev."""
    
    eta0            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    eta             = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    m               = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    P               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))

    y               = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    H               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    Hw              = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    Cy              = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    err             = tf.Variable(tf.zeros((N,n), dtype=tf.float64))

    
    for i in range(N): 

        mi_pred, Pi_pred        = EKF_Predict(xprev[i,:], Pprev[i,:,:], A, V) 
        
        eta[i,:].assign(mi_pred)
        eta0[i,:].assign( norm_rvs(n, mi_pred, Pi_pred + U) )
        m[i,:].assign(mi_pred)
        P[i,:,:].assign(Pi_pred)
        
        yi_pred     = SV_transform(n, muy, B, eta[i,:], W, U)
        y[i,:].assign(yi_pred)
        
        Jxi, Jwi    = EKF_Jacobi(eta[i,:], yi_pred, B)
        H[i,:,:].assign( Jxi )
        Hw[i,:,:].assign( Jwi )
        
        Cy[i,:,:].assign( Jwi @ W @ tf.transpose(Jwi) + U)
        err[i,:].assign( yi_pred - tf.linalg.matvec(Jxi, eta[i,:]) )
        

    return eta, eta0, m, P, y, H, Hw, Cy, err

def LEDH_update_EKF(N, n, m0, P0, y, yhat, Hx, Hw, W, U):
    P               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    for i in range(N): 
        K           = EKF_Gain(P0[i,:,:], Hx[i,:,:], Hw[i,:,:], W, U)
        _, Pi       = EKF_Filter(m0[i,:], P0[i,:,:], y, yhat[i,:], Hx[i,:,:], K)
        P[i,:,:].assign(Pi)
    return P

def LEDH_linearize_UKF(N, n, xprev, Pprev, A, B, V, W, wm, wc, wi, L, U):
    """Predict the pseudo particles, eta and eta0, by UKF using the previous state and its associated particles, xhat and xprev."""
    
    eta0            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    eta             = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    m               = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    P               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))

    y               = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    H               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    Hw              = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    Cy              = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    err             = tf.Variable(tf.zeros((N,n), dtype=tf.float64))

    x_pred0         = tf.Variable(tf.zeros((n*2,), dtype=tf.float64))
    P_pred0         = tf.Variable(tf.zeros((n*2,n*2), dtype=tf.float64))
    P_pred0[n:n*2,n:n*2].assign(W) 
    
    XSP             = tf.Variable(tf.zeros((N,2*(n*2)+1, n*2), dtype=tf.float64))    
    YSP             = tf.Variable(tf.zeros((N,2*(n*2)+1, n), dtype=tf.float64))
    
    for i in range(N): 
        
        Xprev_sp    = SigmaPoints(n, xprev[i,:], Pprev[i,:,:], L)
        X_sp        = Xprev_sp @ tf.transpose(A) 

        mi_pred     = UKF_Predict_mean(wm, wi, X_sp) 
        Pi_pred     = UKF_Predict_cov(n, wc, wi, X_sp, mi_pred, U, Cov=V)  
        
        eta[i,:].assign(mi_pred)
        eta0[i,:].assign( norm_rvs(n, mi_pred, Pi_pred + U) )        
        m[i,:].assign(mi_pred)
        P[i,:,:].assign(Pi_pred)
        
        x_pred0[:n].assign(mi_pred)
        P_pred0[0:n,0:n].assign(Pi_pred)
        
        Xpred_sp    = SigmaPoints(n*2, x_pred0, P_pred0, L)
        XSP[i,:,:].assign(Xpred_sp)
        
        Y_sp        = tf.math.exp(Xpred_sp[:,:n]/2) @ tf.transpose(B) * Xpred_sp[:,n:]
        YSP[i,:,:].assign(Y_sp)
        
        yi_pred     = UKF_Predict_mean(wm, wi, Y_sp)
        y[i,:].assign(yi_pred)
        
        W_pred      = UKF_Predict_cov(n, wc, wi, Y_sp, yi_pred, U)
        Jxi, Jwi    = EKF_Jacobi(eta[i,:], yi_pred, B)
        
        H[i,:,:].assign( Jxi )
        Hw[i,:,:].assign( Jwi )
        
        Cy[i,:,:].assign( W_pred )
        err[i,:].assign( yi_pred - tf.linalg.matvec(Jxi, eta[i,:]) )        
    
    return eta, eta0, m, P, y, H, Hw, Cy, err, XSP, YSP


def LEDH_update_UKF(N, n, m0, P0, y, yhat, Hw, Xsp, Ysp, wc, wi, U):
    P               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    for i in range(N): 
        C_pred      = UKF_Predict_crosscov(n, wc, wi, Xsp[i,:,:n], m0[i,:], Ysp[i,:,:], yhat[i,:], U) 
        K           = UKF_Gain(C_pred, Hw[i,:,:], U)
        _, Pi       = UKF_Filter(m0[i,:], P0[i,:,:], Hw[i,:,:], y, yhat[i,:], K)
        P[i,:,:].assign(Pi)
    return P

def LEDH_flow_dynamics(N, n, Lamb, epsilon, I, eta, eta0, Pi, Hi, Ri, err, y, U):
    """Compute and return the flow dynamics of the pseudo particles for migration."""
    
    move0           = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    move            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    prod            = tf.Variable(tf.zeros((N,), dtype=tf.float64))
    
    for i in range(N):         
        
        Ai          = Li17eq10(Lamb, Hi[i,:,:], Pi[i,:,:], Ri[i,:,:], U)
        bi          = Li17eq11(I, Lamb, Ai, Hi[i,:,:], Pi[i,:,:], Ri[i,:,:], y, err[i,:], eta0[i,:], U)
        
        move0[i,:].assign( epsilon * (tf.linalg.matvec(Ai, eta0[i,:]) + bi) )
        move[i,:].assign( epsilon * (tf.linalg.matvec(Ai, eta[i,:]) + bi) )
        prod[i].assign( tf.math.abs( tf.linalg.det(I + epsilon * Ai) ) )
        
    return move0, move, prod

def LEDH_flow_lp(N, eta0, theta, eta1, xprev, y, SigmaX, muy, SigmaY, U):
    """Compute and return the log posterior of the migrated pseudo particles."""
    Lp              = tf.Variable(tf.zeros((N,), dtype=tf.float64)) 
    for i in range(N):  
        Lp[i].assign( tf.math.log(theta[i]) + LogLikelihood(eta1[i,:], y, muy, SigmaY, U) + LogTarget(eta1[i,:], xprev[i,:], SigmaX[i,:,:]) - LogImportance(eta0[i,:], xprev[i,:], SigmaX[i,:,:]) )  
    return Lp

def LEDH(y, A=None, B=None, V=None, W=None, N=None, mu0=None, Sigma0=None, muy=None, method=None, stepsize=None):
    """
    Compute the estimated states using the LEDH given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The measurements generated by SVSSM. 
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    N : int32, optional. Defaults to 1000 if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims). The prior covariance for initial state. Defaults to predefined covariance using V and A if not provided.
    muy : tf.Tensor of float64 with shape (ndims,), optioanl. The expectation of the measurements. Defaults to zeros if not provided.
    method : str, optional. The linearization method. Defaults to "UKF" if not provided.  
    stepsize : float64, optional. The stepsize in the psuedo time interval [0,1]. Defaults to 1e-3 if not provided. 
    
    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the LEDH. 
    ESS : tf.Variable of float64 with dimension (nTimes,). The effective sample sizes. 
    Weights : tf.Variable of float64 with dmension (nTimes,N). The weights of particles. 
    JacobiX : tf.Variable of float64 with dimension (nTimes,N,ndims,ndims). The pseudo Jacobian matrix with respect to the state. 
    JacobiW : tf.Variable of float64 with dimension (nTimes,N,ndims,ndims). The pseudo Jacobian matrix with respect to the noise. 
    """
    
    nTimes, ndims   = y.shape 

    A               = tf.eye(ndims, dtype=tf.float64) * 0.5 if A is None else A
    if A is not None and tf.reduce_max(A) >= 1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    if A is not None and tf.reduce_min(A) <= -1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W

    mu0             = tf.zeros((ndims,), dtype=tf.float64) if mu0 is None else mu0
    Sigma0          = (V @ V) @ tf.linalg.inv(tf.eye(ndims, dtype=tf.float64) - A @ A) if Sigma0 is None else Sigma0
    muy             = tf.zeros((ndims,), dtype=tf.float64) if muy is None else muy

    N               = 1000 if N is None else N
    Np              = N
    NT              = N/2

    method          = "UKF" if method is None else method 
    weight0_m, weight0_c, weighti, L = SigmaWeights(ndims)
    
    stepsize        = 1e-3 if stepsize is None else stepsize     
    Nl              = 30
    Rates           = [stepsize] + [stepsize * (1.2*i) for i in range(1,30)]
    
    u               = tf.eye(ndims, dtype=tf.float64) * 1e-9
    I               = tf.eye(ndims, dtype=tf.float64)

    JacobiX         = tf.Variable(tf.zeros((nTimes, Np, ndims, ndims), dtype=tf.float64))
    JacobiW         = tf.Variable(tf.zeros((nTimes, Np, ndims, ndims), dtype=tf.float64))
    
    Weights         = tf.Variable(tf.zeros((nTimes, Np), dtype=tf.float64))
    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    ESS             = tf.Variable(tf.zeros((nTimes,), dtype=tf.float64))

    P0              = A @ Sigma0 @ tf.transpose(A) + V
    P_prev          = tf.Variable(tf.zeros((Np,ndims,ndims), dtype=tf.float64))
    for i in range(Np):
        P_prev[i,:,:].assign(P0)

    x_prev          = initiate_particles(Np, ndims, mu0, P0)
    w_prev          = tf.Variable(tf.ones((N,), dtype=tf.float64) / N) 

    for i in range(nTimes): 

        if method == "UKF":        
            eta, eta0, m_pred, P_pred, y_pred, H, Hiw, R, el, xsp, ysp = LEDH_linearize_UKF(Np, ndims, x_prev, P_prev, A, B, V, W, weight0_m, weight0_c, weighti, L, u)
        if method == "EKF":            
            eta, eta0, m_pred, P_pred, y_pred, H, Hiw, R, el = LEDH_linearize_EKF(Np, ndims, x_prev, P_prev, A, B, V, W, muy, u)
        
        JacobiX[i,:,:,:].assign(H)
        JacobiW[i,:,:,:].assign(Hiw)
        
        eta1        = eta0
        theta       = tf.Variable(tf.ones((Np,), dtype=tf.float64))
        Lamb        = 0.0
        for j in range(Nl): 
            eta1_move, eta_move, theta_prod     = LEDH_flow_dynamics(Np, ndims, Lamb, Rates[j], I, eta, eta1, P_pred, H, R, el, y[i,:], u)  
            Lamb += Rates[j]
            eta.assign_add(eta_move)
            eta1.assign_add(eta1_move)
            theta2 = theta * theta_prod
            theta.assign(theta2)
            
        lp          = LEDH_flow_lp(Np, eta0, theta, eta1, x_prev, y[i,:], P_pred, muy, W, u)       
        w_pred      = compute_weights(w_prev, lp)
        w_norm      = normalize_weights(w_pred)        
        ness        = compute_ESS(w_norm)

        ESS[i].assign(ness)
        Weights[i,:].assign(w_norm)   
             
        if ness < NT: 
            xbar, wbar  = multinomial_resample(Np, eta1, w_norm)
            x_filt      = compute_posterior(wbar, xbar)
            x_prev      = xbar
        else: 
            x_filt      = compute_posterior(w_norm, eta1)
            x_prev      = eta1

        X_filtered[i,:].assign(x_filt) 
        
        if method == "UKF":
            P_filt  = LEDH_update_UKF(Np, ndims, m_pred, P_pred, y[i,:], y_pred, R, xsp, ysp, weight0_c, weighti, u) 
        if method == "EKF":    
            P_filt  = LEDH_update_EKF(Np, ndims, m_pred, P_pred, y[i,:], y_pred, H, Hiw, W, u)
        P_prev      = P_filt
        
    return X_filtered, ESS, Weights, JacobiX, JacobiW









#####################################
# Particle Flow Filter - Kernel PFF # 
#####################################



def Hu21eq13(y, ypred, Jx, Jw, W, U):
    Rinv            = tf.linalg.inv( Jw @ W @ tf.transpose(Jw) + U )  
    return tf.linalg.matvec( tf.transpose(Jx) @ Rinv, y - ypred) # Jx = (n,nx)

def Hu21eq15(xpred, x0, Sigma0, U):
    return tf.linalg.matvec( tf.linalg.inv(Sigma0 + U), xpred - x0)

def KPFF_LP(N, nx, n, x, y, muy, B, W, mu0, Sigma0, U, Uy):
    JxC             = tf.Variable(tf.zeros((N,n,nx), dtype=tf.float64)) 
    JwC             = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64)) 
    LP              = tf.Variable(tf.zeros((N,nx), dtype=tf.float64))
    for i in range(N):
        
        yi_pred     = SV_transform(n, muy, B, x[i,:], W, Uy)         
        Hx, Hw      = EKF_Jacobi(x[i,:], yi_pred, B)  
        
        Hxj         = tf.reshape(tf.linalg.diag_part(Hx), [n,1])
        Jx          = tf.tile(tf.reshape(Hxj,[n,1]), [1,nx]) 
                       
        lpi         = Hu21eq13(y, yi_pred, Jx, Hw, W, Uy) - Hu21eq15(x[i,:], mu0, Sigma0, U)
        
        LP[i,:].assign(lpi)
        JxC[i,:,:].assign( Jx)
        JwC[i,:,:].assign( Hw )
    return LP, JxC, JwC

def KPFF_RKHS(N, n, x, Lp, Sigma0):
    In              = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    for i in range(n): 
        K, Kc       = SE_Cov_div(N, x[:,i], length=Sigma0[i,i])
        for j in range(N): 
            In[j,i].assign( tf.reduce_sum(1/N * ( Lp[j,i] * K[j,:] + Kc[j,:] * K[j,:] )) )
    return In

def KPFF_flow(N, n, epsilon, integral, Sigma0):
    xadd            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    for i in range(N):
        field       = tf.linalg.matvec( Sigma0, integral[i,:] )
        xadd[i,:].assign( epsilon * field )
    return xadd 


def KernelPFF(y, Nx, A=None, B=None, V=None, W=None, N=None, mu0=None, Sigma0=None, muy=None, method=None, stepsize=None):
    """
    Compute the estimated states using the Kernel PFF given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The measurements generated by SVSSM. 
    A : tf.Tensor of float64 with shape (Nx,Nx), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    B : tf.Tensor of float64 with shape (ndims,Nx), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (Nx,Nx), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    N : int32, optional. Defaults to 1000 if not provided.
    mu0 : tf.Tensor of float64 with shape (Nx,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (Nx,Nx). The prior covariance for initial state. Defaults to predefined covariance using V and A if not provided.
    muy : tf.Tensor of float64 with shape (ndims,), optioanl. The expectation of the measurements. Defaults to zeros if not provided.
    method : str, optional. The linearization method. Defaults to "kernel" if not provided.  
    stepsize : float64, optional. The stepsize in the psuedo time interval [0,1]. Defaults to 1e-3 if not provided. 
    
    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,Nx). The filtered states given by the Kernel PFF.
    JacobiX : tf.Variable of float64 with dimension (nTimes,Nl,N,ndims,Nx). The pseudo Jacobian matrix with respect to the state. 
    JacobiW : tf.Variable of float64 with dimension (nTimes,Nl,N,ndims,ndims). The pseudo Jacobian matrix with respect to the noise. 
    X_part : tf.Variable of float64 with dimension (nTimes,N,Nx). The prior particles given by the Kernel PFF.
    X_part2 : tf.Variable of float64 with dimension (nTimes,N,Nx). The posterior particles given by the Kernel PFF.
    """
    
    nTimes, ndims   = y.shape 
    
    A               = tf.eye(Nx, dtype=tf.float64) * 0.5 if A is None else A
    if A is not None and tf.reduce_max(A) >= 1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    if A is not None and tf.reduce_min(A) <= -1.0:
        raise ValueError("The matrix A out of range (-1,1).")
    
    B               = tf.ones((ndims, Nx), dtype=tf.float64) if B is None else B
    
    V               = tf.eye(Nx, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W

    mu0             = tf.zeros((Nx,), dtype=tf.float64) if mu0 is None else mu0
    Sigma0          = (V @ V) @ tf.linalg.inv(tf.eye(Nx, dtype=tf.float64) - A @ A) if Sigma0 is None else Sigma0
    muy             = tf.zeros((ndims,), dtype=tf.float64) if muy is None else muy

    N               = 1000 if N is None else N
    Np              = N
    
    method          = "kernel" if method is None else method 

    stepsize        = 1e-3 if stepsize is None else stepsize     
    Nl              = 30
    Rates           = [stepsize] + [stepsize * (1.2*i) for i in range(1,30)]
    
    u               = tf.eye(Nx, dtype=tf.float64) * 1e-9
    uy              = tf.eye(ndims, dtype=tf.float64) * 1e-9

    X_filtered      = tf.Variable(tf.zeros((nTimes,Nx), dtype=tf.float64))   
    X_part          = tf.Variable(tf.zeros((nTimes,N,Nx), dtype=tf.float64))
    X_part2         = tf.Variable(tf.zeros((nTimes,N,Nx), dtype=tf.float64))
    
    JacobiX         = tf.Variable(tf.zeros((nTimes, Nl, Np, ndims,Nx), dtype=tf.float64))  
    JacobiW         = tf.Variable(tf.zeros((nTimes, Nl, Np, ndims,ndims), dtype=tf.float64))  
    
    for i in range(nTimes): 
        
        x_prev      = initiate_particles(Np, Nx, mu0, Sigma0)
        x_hat       = tf.Variable(tf.reduce_mean(x_prev, axis=0))
        
        X_part[i,:,:].assign(x_prev)

        for j in range(Nl): 
            
            grad, Jx, Jw = KPFF_LP(Np, Nx, ndims, x_prev, y[i,:], muy, B, W, x_hat, Sigma0, u, uy)
            
            if method == "kernel":
                II  = KPFF_RKHS(Np, Nx, x_prev, grad, Sigma0)
            if method == "scalar":
                II  = grad / Np

            x_move  = KPFF_flow(Np, Nx, Rates[j], II, Sigma0)
            x_prev.assign_add(x_move) 
            
            JacobiX[i,j,:,:,:].assign( Jx )
            JacobiW[i,j,:,:,:].assign( Jw )

        x_hat       = tf.Variable( tf.reduce_mean(x_prev, axis=0) )   
        
        X_part2[i,:,:].assign(x_prev)         
        X_filtered[i,:].assign(x_hat)

    return X_filtered, JacobiX, JacobiW, X_part, X_part2













