import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import tensorflow_probability as tfp
tfd = tfp.distributions

from .model import initiate_particles, norm_rvs, measurements_pred, measurements_Jacobi, measurements_covyHat, SE_Cov_div
from .functions2 import LEDH_SDE_Hessians, LEDH_SDE_flow_dynamics, soft_resample

##########################
# Standard Kalman Filter # 
##########################

def KF_Predict(x_prev, P_prev, A, V):
    "Predict and return the system state and covariance matrix, x and P, given the previous, x_prev and P_prev."
    x               = tf.linalg.matvec(A, x_prev)
    P               = A @ P_prev @ tf.transpose(A) + V
    return x, P 

def KF_Gain(P, B, W):
    "Compute and return the standard Kalman gain."
    M               = P @ tf.transpose(B) 
    Minv            = tf.linalg.inv(B @ M + W) 
    return M @ Minv

def KF_Filter(x_prev, P_prev, y_obs, y_prev, B, K):
    "Filter the predicted system state and covariance matrix, x_prev and P_prev, using the Kalman gain and observed measurments, K and y_obs."
    x               = x_prev + tf.linalg.matvec(K, y_obs - y_prev)
    P               = P_prev - P_prev @ tf.transpose(B) @ tf.transpose(K)
    return x, P

def KalmanFilter(y, A=None, B=None, V=None, W=None, mu0=None, Sigma0=None):
    """
    Compute the estimated states using the standard Kalman Filter given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The measurements generated by LGSSM. 
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to identity matrix if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims), optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optional. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims), optional. The prior covariance for initial state. Defaults to identity matrix if not provided.

    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the standard Kalman Filter. 
    """
    nTimes, ndims   = y.shape 
    mu0             = tf.zeros((ndims,), dtype=tf.float64) if mu0 is None else mu0
    Sigma0          = tf.eye(ndims, dtype=tf.float64) if Sigma0 is None else Sigma0
    A               = tf.eye(ndims, dtype=tf.float64) if A is None else A
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W
    
    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    x_prev          = norm_rvs(ndims, mu0, Sigma0) 
    P_prev          = A @ Sigma0 @ tf.transpose(A) + V

    for i in range(nTimes):
        x_pred, P_pred     = KF_Predict(x_prev, P_prev, A, V)
        K                  = KF_Gain(P_pred, B, W)
        y_pred             = tf.linalg.matvec(B, x_pred)
        x_filt, P_filt     = KF_Filter(x_pred, P_pred, y[i,:], y_pred, B, K)
        x_prev, P_prev     = x_filt, P_filt        
        X_filtered[i,:].assign(x_prev)  
        
    return X_filtered


##########################
# Extended Kalman Filter # 
##########################


def EKF_Predict(x_prev, P_prev, A, V):
    "Predict and return the system state and covariance matrix, x and P, given the previous, x_prev and P_prev."
    x               = tf.linalg.matvec(A, x_prev)
    P               = A @ P_prev @ tf.transpose(A) + V
    return x, P 

def EKF_Gain(P, Jx, Jw, W, U):
    """Compute and return the Extended Kalman gain."""
    Mx              = P @ tf.transpose(Jx)
    J               = Jx @ Mx + Jw @ W @ tf.transpose(Jw)
    Minv            = tf.linalg.inv(J + U) 
    return Mx @ Minv

def EKF_Filter(x_prev, P_prev, y_obs, y_prev, Jx, K):
    """Filter the predicted system state and covariance matrix, x_prev and P_prev, using the Kalman gain and observed measurments, K and y_obs."""
    x               = x_prev + tf.linalg.matvec(K, y_obs - y_prev)
    P               = P_prev - P_prev @ tf.transpose(Jx) @ tf.transpose(K) 
    return x, P

def ExtendedKalmanFilter(y, model=None, A=None, B=None, V=None, W=None, mu0=None, Sigma0=None, muy=None):
    """
    Compute the estimated states using the Extended Kalman Filter given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The observed measurements. 
    model: string, optional. The name of the measurement model. Defaults to linear Gaussian "LG" if not provided. 
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims). The prior covariance for initial state. Defaults to predefined covariance if not provided.
    muy : tf.Tensor of float64 with shape (ndims,), optioanl. The scalar means of the measurements. Defaults to zeros if not provided.
    
    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the Extended Kalman Filter. 
    """
    nTimes, ndims   = y.shape     
    
    model           = "LG" if model is None else model
    if model == "sensor" and ndims != 2:
        raise ValueError("The state space dimension must be 2 for the location sensoring model.")
        
    if model == "SV" and A is None : 
        A           = tf.eye(ndims, dtype=tf.float64) * 0.5  
    if model == "SV" and A is not None :
        if tf.reduce_max(A) > 1.0:
            raise ValueError("The matrix A out of range [-1,1].")
        if tf.reduce_min(A) < -1.0:
            raise ValueError("The matrix A out of range [-1,1].")
    if model != "SV" and A is None : 
        A           = tf.eye(ndims, dtype=tf.float64) 
    
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W
    

    if model == "sensor" and mu0 is None:
        mu0         = tf.constant([3.0,5.0], dtype=tf.float64) 
    else:
        mu0         = tf.zeros((ndims,), dtype=tf.float64)     
        
    if model == "SV" and Sigma0 is None :
        Sigma0      = V @ tf.linalg.inv(tf.eye(ndims, dtype=tf.float64) - A @ A)  
    if model != "SV" and Sigma0 is None: 
        Sigma0      = V
        
    muy             = tf.zeros((ndims,), dtype=tf.float64) if muy is None else muy

    u               = tf.eye(ndims, dtype=tf.float64) * 1e-9
    I1              = tf.ones((ndims,), dtype=tf.float64)

    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))

    x_prev          = norm_rvs(ndims, mu0, Sigma0) 
    P_prev          = A @ Sigma0 @ tf.transpose(A) + V
    
    for i in range(nTimes):
        x_pred, P_pred              = EKF_Predict(x_prev, P_prev, A, V)

        y_pred                      = measurements_pred(model, ndims, muy, B, x_pred, W, u)
        Jx, Jw                      = measurements_Jacobi(model, I1, x_pred, y_pred, B)

        K                           = EKF_Gain(P_pred, Jx, Jw, W, u)
        x_filt, P_filt              = EKF_Filter(x_pred, P_pred, y[i,:], y_pred, Jx, K)
        x_prev, P_prev              = x_filt, P_filt        
        X_filtered[i,:].assign(x_prev) 
        
    return X_filtered


###########################
# Unscented Kalman Filter # 
###########################
    
def SigmaWeights(ndims, alpha=None, kappa=None, beta=None):
    """Compute and return the weights of sigma-points."""
    alpha           = 1.0 if alpha is None else alpha
    kappa           = 3.0 * ndims / 2.0 if kappa is None else kappa
    beta            = 2.0 if beta is None else beta

    Lambda          = (alpha**2) * kappa
    w0m             = (Lambda - ndims) / Lambda 
    w0c             = w0m + (1 - alpha**2 + beta)
    wi              = 1 / (2*Lambda)    
    return w0m, w0c, wi, Lambda

def SigmaPoints(ndims, xhat, Phat, Lambda):  
    """Compute and return a set of 2*ndims+1 sigma-points for each state."""
    sqrtMat         = tf.linalg.cholesky(Lambda * Phat) 
    SP              = tf.Variable(tf.zeros((2*ndims+1, ndims), dtype=tf.float64))
    SP[0,:].assign(xhat)
    for i in range(1,ndims+1):
        SP[i,:].assign( xhat + sqrtMat[:,i-1] )
        SP[ndims+i,:].assign( xhat - sqrtMat[:,i-1] ) 
    return SP

def UKF_Propagate(model, ndims, X_sp, B):
    """Propagate the sigma points of states, X_sp, through the specified measurement model."""
    if model =="LG" :
        return X_sp @ tf.transpose(B)  
    if model == "SV" : 
        return tf.math.exp(X_sp[:,:ndims]/2) @ tf.transpose(B) * X_sp[:,ndims:]

def UKF_Predict_mean(weight0m, weighti, SP):
    """Compute and return the estimated mean of the transformed variables."""
    return weight0m * SP[0,:] + tf.reduce_sum( weighti * SP[1:,:], axis=0 )

def UKF_Predict_cov(ndims, weight0c, weighti, SP, mean, u, Cov=None):
    """Compute and return the estimated covariance of the transformed variables."""
    Cov             = tf.zeros((len(mean),len(mean)), dtype=tf.float64) if Cov is None else Cov 
    diffs           = SP - mean 
    cov1            = weight0c * tf.tensordot(diffs[0,:], diffs[0,:], axes=0)
    for i in range(1,ndims+1):
        cov1        += weighti * tf.tensordot(diffs[i,:], diffs[i,:], axes=0)
        cov1        += weighti * tf.tensordot(diffs[ndims+i,:], diffs[ndims+i,:], axes=0)
    return cov1 + Cov + u
    
def UKF_Predict_crosscov(ndims, weight0c, weighti, SP, mean, SP2, mean2, u):
    """Compute and return the estimated cross-covariance of the transformed variables."""
    diffs           = SP - mean
    diffs2          = SP2 - mean2
    cov             = weight0c * tf.tensordot(diffs[0,:], diffs2[0,:], axes=0)
    for i in range(1,ndims+1):       
        cov         += weighti * tf.tensordot(diffs[i,:], diffs2[i,:], axes=0)
        cov         += weighti * tf.tensordot(diffs[ndims+i,:], diffs2[ndims+i,:], axes=0)
    return cov + u

def UKF_Predict(model, ndims, xpred, Ppred, w0m, w0c, wi, Lamb, B, W, U):
    """Compute and return the estimated means, covariance and cross-covariance of the transformed variables with additive noises."""
    if model == "LG":
        ndims2  = ndims 
    else:
        ndims2  = ndims * 2
    Xpred_sp    = SigmaPoints(ndims2, xpred, Ppred, Lamb)
    Y_sp        = UKF_Propagate(model, ndims, Xpred_sp, B) 
    y_pred      = UKF_Predict_mean(w0m, wi, Y_sp)
    W_pred      = UKF_Predict_cov(ndims2, w0c, wi, Y_sp, y_pred, U, Cov=W)
    C_pred      = UKF_Predict_crosscov(ndims2, w0c, wi, Xpred_sp[:,:ndims], xpred[:ndims], Y_sp, y_pred, U) 
    return y_pred, W_pred, C_pred

def UKF_Gain(Cn, Wn, u):
    """Compute and return the unscented Kalman gain."""
    M           =  tf.linalg.inv(Wn + u)
    return Cn @ M

def UKF_Filter(x1, P1, Wn, y_obs, y_pred, K):
    """Filter the predicted system state and covariance matrix, x1 and P1, using the Kalman gain and observed measurments, K and y_obs."""
    x               = x1 + tf.linalg.matvec(K, y_obs - y_pred)
    P               = P1 - K @ Wn @ tf.transpose(K)
    return x, P

def UnscentedKalmanFilter(y, model=None, A=None, B=None, V=None, W=None, mu0=None, Sigma0=None):
    """
    Compute the estimated states using the Unscented Kalman Filter given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The observed measurements. 
    model: string, optional. The name of the measurement model. Defaults to linear Gaussian "LG" if not provided.A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims). The prior covariance for initial state. Defaults to predefined covariance if not provided.
    
    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the Unscented Kalman Filter. 
    """

    nTimes, ndims   = y.shape 

    model           = "LG" if model is None else model
    if model == "sensor" and ndims != 2:
        raise ValueError("The state space dimension must be 2 for the location sensoring model.")
    
    if model == "SV" and A is None : 
        A           = tf.eye(ndims, dtype=tf.float64) * 0.5  
    if model == "SV" and A is not None :
        if tf.reduce_max(A) > 1.0:
            raise ValueError("The matrix A out of range [-1,1].")
        if tf.reduce_min(A) < -1.0:
            raise ValueError("The matrix A out of range [-1,1].")
    if model != "SV" and A is None : 
        A           = tf.eye(ndims, dtype=tf.float64) 
    
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W

    if model == "sensor" and mu0 is None:
        mu0         = tf.constant([3.0,5.0], dtype=tf.float64) 
    else:
        mu0         = tf.zeros((ndims,), dtype=tf.float64)     
        
    if model == "SV" and Sigma0 is None :
        Sigma0      = V @ tf.linalg.inv(tf.eye(ndims, dtype=tf.float64) - A @ A)  
    if model != "SV" and Sigma0 is None: 
        Sigma0      = V
    
    u               = tf.eye(ndims, dtype=tf.float64) * 1e-9    
    weight0_m, weight0_c, weighti, L = SigmaWeights(ndims) 
    if model == "SV":
        x_pred0     = tf.Variable(tf.zeros((ndims*2,), dtype=tf.float64))
        P_pred0     = tf.Variable(tf.zeros((ndims*2,ndims*2), dtype=tf.float64))
        P_pred0[ndims:ndims*2,ndims:ndims*2].assign(W) 
    if model == "LG":
        x_pred0     = tf.Variable(tf.zeros((ndims,), dtype=tf.float64))
        P_pred0     = tf.Variable(tf.zeros((ndims,ndims), dtype=tf.float64))
    
    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    
    x_prev          = norm_rvs(ndims, mu0, Sigma0) 
    P_prev          = A @ Sigma0 @ tf.transpose(A) + V

    for i in range(nTimes):

        Xprev_sp    = SigmaPoints(ndims, x_prev, P_prev, L)
        X_sp        = Xprev_sp @ tf.transpose(A) 
        x_pred      = UKF_Predict_mean(weight0_m, weighti, X_sp) 
        P_pred      = UKF_Predict_cov(ndims, weight0_c, weighti, X_sp, x_pred, u, Cov=V)  

        if model == "SV":
            x_pred0[:ndims].assign(x_pred)
            P_pred0[:ndims,:ndims].assign(P_pred)
        if model == "LG": 
            x_pred0 = x_pred 
            P_pred0 = P_pred 

        y_pred, W_pred, C_pred = UKF_Predict(model, ndims, x_pred0, P_pred0, weight0_m, weight0_c, weighti, L, B, W, u)
        K                      = UKF_Gain(C_pred, W_pred, u)
        x_filt, P_filt         = UKF_Filter(x_pred, P_pred, W_pred, y[i,:], y_pred, K)
        x_prev, P_prev         = x_filt, P_filt  

        X_filtered[i,:].assign(x_prev)         
        
    return X_filtered


################### 
# Particle Filter # 
################### 

def LogImportance(x, mu0, Sigma0):
    """Compute and return the log probability of the state vector, x, using the importance distribution given the mean, mu0, and the covariance, Sigma0."""
    InvSigma0       = tf.linalg.inv(Sigma0)
    diff            = x - mu0
    return - 1/2 * tf.math.log(tf.linalg.det(Sigma0)) - 1/2 * tf.linalg.tensordot( tf.linalg.matvec(InvSigma0, diff), diff, axes=1) 

def LogLikelihood(y, muy, Sigma, U):
    """Compute and return the log likelihood of the measurement model given the measurement mean, muy, and the covariance, Sigma. """
    InvCi           = tf.linalg.inv(Sigma + U)
    detCi           = tf.linalg.det(Sigma)
    return - 1/2 * tf.math.log(detCi) - 1/2 * tf.linalg.tensordot( tf.linalg.matvec(InvCi, (y - muy)), (y - muy), axes=1) 

def LogTarget(x, xprev, Sigma0):
    """Compute and return the log probability of the state vector, x, using the target distribution given the previous state, xprev, and the covariance, Sigma0."""
    InvSigma0       = tf.linalg.inv(Sigma0)
    diff            = x - xprev
    return - 1/2 *  tf.math.log(tf.linalg.det(Sigma0)) - 1/2 * tf.linalg.tensordot( tf.linalg.matvec(InvSigma0, diff), diff, axes=1) 

def draw_particles(N, n, model, I, y, xprev, SigmaX, muy, SigmaY, Sigma0, B, U):
    """Draw particles, xn, from the importance distribution and compute the log posterior probability, Lp."""
    xn              = tf.Variable(tf.zeros((N,n), dtype=tf.float64)) 
    Lp              = tf.Variable(tf.zeros((N,), dtype=tf.float64)) 
    for i in range(N):  
        xi          = norm_rvs(n, xprev[i,:], Sigma0) 
        xn[i,:].assign(xi)
        _, Jw       = measurements_Jacobi(model, I, xprev[i,:], y, B)
        Cy          = measurements_covyHat(model, Jw, SigmaY)
        mu          = measurements_pred(model, n, muy, B, xi, SigmaY, U)
        Lp[i].assign( LogLikelihood(y, mu, Cy, U) + LogTarget(xi, xprev[i,:], SigmaX) - LogImportance(xi, xprev[i,:], Sigma0) )      
    return xn, Lp 

def compute_weights(w0, Lp):
    """Compute and return the importance weights using the previous weights, w0, and the log posterior probability, Lp."""
    return tf.math.exp( tf.math.log(w0) + Lp )

def normalize_weights(w):
    """Normalize the weights, w, and return the normalized weights that sum up to one."""
    return w / tf.reduce_sum(w)

def compute_ESS(w):
    """Compute and return the effective sample size using the normalized weights, w."""
    return 1 / tf.reduce_sum(w**2)

def multinomial_resample(N, x, w):
    """Resample from the set of particles, x, using the weights, w, as multinomial probabilities and return the new set of particles, xbar, and the new weights, wbar."""
    dist            = tfd.Categorical(probs=w)
    indices         = dist.sample(N)
    xbar            = tf.gather(x, indices)
    wbar            = tf.ones((N,), dtype=tf.float64) / N 
    return xbar, wbar 

def compute_posterior(w, x):
    "Compute and return the posterior estimates of the state using the weights, w, and the particles, x. "
    return tf.linalg.matvec( tf.transpose(x), w ) 


def ParticleFilter(y, model=None, A=None, B=None, V=None, W=None, N=None, multi_resample=True, soft_resample=False, Lamb=None, mu0=None, Sigma0=None, muy=None):
    """
    Compute the estimated states using the standard Particle Filter given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The observed measurements. 
    model: string, optional. The name of the measurement model. Defaults to linear Gaussian "LG" if not provided.A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    N : int32, optional. Defaults to 1000 if not provided.
    resample : Bool, optional. The choice to perform resampling. Defaults to True. 
    mu0 : tf.Tensor of float64 with shape (ndims,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims). The prior covariance for initial state. Defaults to predefined covariance if not provided.
    muy : tf.Tensor of float64 with shape (ndims,), optioanl. The scalar means of the measurements. Defaults to zeros if not provided.
    
    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the standard Particle Filter. 
    ESS : tf.Variable of float64 with dimension (nTimes,). The effective sample sizes before resampling. 
    Weights : tf.Variable of float64 with dimension (nTimes,N). The normalized weights of particles before resampling.
    X_part : tf.Variable of float64 with dimension (nTimes,N,ndims). The particles before resampling.
    X_part2 : tf.Variable of float64 with dimension (nTimes,N,ndims). THe particles after resampling.
    """
    
    nTimes, ndims   = y.shape 
    
    model           = "LG" if model is None else model
    if model == "sensor" and ndims != 2:
        raise ValueError("The state space dimension must be 2 for the location sensoring model.")
    
    if model == "SV" and A is None : 
        A           = tf.eye(ndims, dtype=tf.float64) * 0.5  
    if model == "SV" and A is not None :
        if tf.reduce_max(A) > 1.0:
            raise ValueError("The matrix A out of range [-1,1].")
        if tf.reduce_min(A) < -1.0:
            raise ValueError("The matrix A out of range [-1,1].")
    if model != "SV" and A is None : 
        A           = tf.eye(ndims, dtype=tf.float64) 
    
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W
    
    if model == "sensor" and mu0 is None:
        mu0         = tf.constant([3.0,5.0], dtype=tf.float64) 
    else:
        mu0         = tf.zeros((ndims,), dtype=tf.float64)  
        
    if model == "SV" and Sigma0 is None :
        Sigma0      = V @ tf.linalg.inv(tf.eye(ndims, dtype=tf.float64) - A @ A)  
    if model != "SV" and Sigma0 is None: 
        Sigma0      = V
        
    muy             = tf.zeros((ndims,), dtype=tf.float64) if muy is None else muy
    Lamb            = 0.5 if Lamb is None else Lamb
    N               = 1000 if N is None else N
    NT              = N/2
    u               = tf.eye(ndims, dtype=tf.float64) * 1e-9
    I               = tf.ones((ndims,), dtype=tf.float64)

    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    ESS             = tf.Variable(tf.zeros((nTimes,), dtype=tf.float64))
    Weights         = tf.Variable(tf.zeros((nTimes,N), dtype=tf.float64))
    X_part          = tf.Variable(tf.zeros((nTimes,N,ndims), dtype=tf.float64))
    X_part2         = tf.Variable(tf.zeros((nTimes,N,ndims), dtype=tf.float64))
    
    x_prev          = initiate_particles(N, ndims, mu0, Sigma0)
    w_prev          = tf.Variable(tf.ones((N,), dtype=tf.float64) / N) 

    for i in range(nTimes):
        
        x_pred, lp  = draw_particles(N, ndims, model, I, y[i,:], x_prev, V, muy, W, Sigma0, B, u)

        w_pred      = compute_weights(w_prev, lp)
        w_norm      = normalize_weights(w_pred) 
        
        Weights[i,:].assign(w_norm)
        X_part[i,:,:].assign(x_pred)
        
        ness        = compute_ESS(w_norm)
        ESS[i].assign(ness)
        
        if multi_resample and ness < NT: 
            xbar, wbar  = multinomial_resample(N, x_pred, w_norm)
            x_filt      = compute_posterior(wbar, xbar)
            x_prev      = xbar
        elif soft_resample and ness < NT:
            xbar, wbar  = soft_resample(N, x_pred, w_norm, Lamb) 
            x_filt      = compute_posterior(w_norm, x_pred)
            x_prev      = x_pred

        X_part2[i,:,:].assign(x_prev)
        X_filtered[i,:].assign(x_filt)

    return X_filtered, ESS, Weights, X_part, X_part2 



##############################
# Particle Flow Filter - EDH # 
##############################


def Li17eq10(L, H, P, R, U):
    """Compute and return the first component, A, of the particle flow dynamics, Ax + b, under the assumption of linear Gaussian."""
    C               = tf.linalg.inv( L * H @ P @ tf.transpose(H) + R + U )
    return -1/2 * P @ tf.transpose(H) @ C @ H 

def Li17eq11(I, L, A, H, P, R, y, ei, e0i, U):
    """Compute and return the second component, b, of the particle flow dynamics, Ax + b, under the assumption of linear Gaussian."""
    M1          = (I + 2*L * A) 
    M2          = (I + L * A) @ P @ tf.transpose(H) @ tf.linalg.inv(R + U)
    v           = tf.linalg.matvec(M2, (y - ei)) + tf.linalg.matvec(A, e0i)
    return tf.linalg.matvec(M1, v)


def EDH_linearize_EKF(N, n, xprev, xhat, Pprev, A, V, U): 
    """Predict the pseudo particles, eta and eta0, by EKF using the previous state and its associated particles, xhat and xprev."""
    m_pred, P_pred  = EKF_Predict(xhat, Pprev, A, V) 
    eta             = tf.Variable(m_pred)
    eta0            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    for i in range(N):
        eta0[i,:].assign( norm_rvs(n, xprev[i,:], P_pred + U) )    
    return eta, eta0, m_pred, P_pred 


def EDH_linearize_UKF(N, n, xprev, xhat, Pprev, A, V, wm, wc, wi, L, U):
    """Predict the pseudo particles, eta and eta0, by UKF using the previous state and its associated particles, xhat and xprev."""
        
    Xprev_sp        = SigmaPoints(n, xhat, Pprev, L)
    X_sp            = Xprev_sp @ tf.transpose(A) 
    
    m_pred          = UKF_Predict_mean(wm, wi, X_sp) 
    P_pred          = UKF_Predict_cov(n, wc, wi, X_sp, m_pred, U, Cov=V)  
    
    eta             = tf.Variable(m_pred) 
    eta0            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    for i in range(N): 
        eta0[i,:].assign( norm_rvs(n, xprev[i,:], P_pred + U) )   
        
    return eta, eta0, m_pred, P_pred 


def EDH_flow_dynamics(N, n, Lamb, epsilon, I, e, e0, P, H, R, er, y, U):
    """Compute and return the flow dynamics of the pseudo particles under linear Gaussian for migration."""
    Ai              = Li17eq10(Lamb, H, P, R, U)
    bi              = Li17eq11(I, Lamb, Ai, H, P, R, y, er, e, U)
    move0           = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    for i in range(N): 
        move0[i,:].assign( epsilon * (tf.linalg.matvec(Ai, e0[i,:]) + bi) )  
    move            = epsilon * (tf.linalg.matvec(Ai, e) + bi) 
    return move0, move

def EDH_flow_lp(N, eta0, eta1, xprev, y, SigmaX, muy, SigmaY, U):
    """Compute and return the log posterior of the migrated pseudo particles."""
    Lp              = tf.Variable(tf.zeros((N,), dtype=tf.float64)) 
    for i in range(N):  
        Lp[i].assign( LogLikelihood(y, muy, SigmaY, U) + LogTarget(eta1[i,:], xprev[i,:], SigmaX) - LogImportance(eta0[i,:], xprev[i,:], SigmaX) )  
    return Lp



def EDH(y, model=None, A=None, B=None, V=None, W=None, N=None, Nstep=None, mu0=None, Sigma0=None, muy=None, method=None, stepsize=None):
    """
    Compute the estimated states using the EDH given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The observed measurements. 
    model: string, optional. The name of the measurement model. Defaults to linear Gaussian "LG" if not provided.A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    N : int32, optional. Number of particles. Defaults to 1000 if not provided.
    Nstep : int32, optional. Number of steps in the psuedo time interval [0,1]. Defaults to 30 if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims). The prior covariance for initial state. Defaults to predefined covariance if not provided.
    muy : tf.Tensor of float64 with shape (ndims,), optioanl. The scalar means of the measurements. Defaults to zeros if not provided.
    method : str, optional. The linearization method. Defaults to "EKF" if not provided.  
    stepsize : float64, optional. The first stepsize in the psuedo time interval [0,1]. Defaults to 1e-3 if not provided. 
    
    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the EDH.
    ESS : tf.Variable of float64 with dimension (nTimes,). The effective sample sizes before resampling. 
    Weights : tf.Variable of float64 with dimension (nTimes,N). The weights of the particles before resampling. 
    JacobiX : tf.Variable of float64 with dimension (nTimes,ndims,ndims). The pseudo Jacobian matrix with respect to the state. 
    JacobiW : tf.Variable of float64 with dimension (nTimes,ndims,ndims). The pseudo Jacobian matrix with respect to the noise. 
    """
    
    nTimes, ndims   = y.shape 
    model           = "LG" if model is None else model
    if model == "sensor" and ndims != 2:
        raise ValueError("The state space dimension must be 2 for the location sensoring model.")
    
    if model == "SV" and A is None : 
        A           = tf.eye(ndims, dtype=tf.float64) * 0.5  
    if model == "SV" and A is not None :
        if tf.reduce_max(A) > 1.0:
            raise ValueError("The matrix A out of range [-1,1].")
        if tf.reduce_min(A) < -1.0:
            raise ValueError("The matrix A out of range [-1,1].")
    if model != "SV" and A is None : 
        A           = tf.eye(ndims, dtype=tf.float64) 
    
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W
    
    if model == "sensor" and mu0 is None:
        mu0         = tf.constant([3.0,5.0], dtype=tf.float64) 
    else:
        mu0         = tf.zeros((ndims,), dtype=tf.float64)   
        
    if model == "SV" and Sigma0 is None :
        Sigma0      = V @ tf.linalg.inv(tf.eye(ndims, dtype=tf.float64) - A @ A)  
    if model != "SV" and Sigma0 is None: 
        Sigma0      = V
        
    muy             = tf.zeros((ndims,), dtype=tf.float64) if muy is None else muy
    
    N               = 1000 if N is None else N
    Np              = N
    NT              = N/2
    
    weight0_m, weight0_c, weighti, L = SigmaWeights(ndims)
    
    method          = "EKF" if method is None else method 
    stepsize        = 1e-3 if stepsize is None else stepsize     
    Nstep           = 30 if Nstep is None else Nstep
    Steps           = tf.constant([stepsize * (1.2*i) for i in range(Nstep+1)], dtype=tf.float64)
    Rates           = tf.math.cumsum(Steps) 
    
    u               = tf.eye(ndims, dtype=tf.float64) * 1e-9
    I               = tf.eye(ndims, dtype=tf.float64)
    I1              = tf.ones((ndims,), dtype=tf.float64)

    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))
    ESS             = tf.Variable(tf.zeros((nTimes,), dtype=tf.float64))
    Weights         = tf.Variable(tf.zeros((nTimes, Np), dtype=tf.float64))
    
    Jacobi_X        = tf.Variable(tf.zeros((nTimes,ndims,ndims), dtype=tf.float64))
    Jacobi_W        = tf.Variable(tf.zeros((nTimes,ndims,ndims), dtype=tf.float64))
    
    x_filt          = tf.Variable(mu0, dtype=tf.float64)
    P_prev          = A @ Sigma0 @ tf.transpose(A) + V 
    x_prev          = initiate_particles(Np, ndims, x_filt, P_prev)
    w_prev          = tf.Variable(tf.ones((N,), dtype=tf.float64) / N) 

    for i in range(nTimes): 

        if method == "UKF":        
            eta, eta0, m_pred, P_pred   = EDH_linearize_UKF(Np, ndims, x_prev, x_filt, P_prev, A, V, weight0_m, weight0_c, weighti, L, u)
            x_pred0                     = tf.Variable(tf.zeros((ndims*2,), dtype=tf.float64))
            P_pred0                     = tf.Variable(tf.zeros((ndims*2,ndims*2), dtype=tf.float64))            
            
            if model == "SV" :
                x_pred0[:ndims].assign(m_pred)
                P_pred0[ndims:ndims*2,ndims:ndims*2].assign(W)     
                P_pred0[0:ndims,0:ndims].assign(P_pred)
            else: 
                x_pred0                 = m_pred 
                P_pred0                 = P_pred 
            
            y_pred, R, Rcross           = UKF_Predict(model, ndims, x_pred0, P_pred0, weight0_m, weight0_c, weighti, L, B, W, u)
            H, Hw                       = measurements_Jacobi(model, I1, m_pred, y_pred, B)

        if method == "EKF":            
            eta, eta0, m_pred, P_pred   = EDH_linearize_EKF(Np, ndims, x_prev, x_filt, P_prev, A, V, u)
            y_pred                      = measurements_pred(model, ndims, muy, B, m_pred, W, u) 
            H, Hw                       = measurements_Jacobi(model, I1, m_pred, y_pred, B)
            R                           = measurements_covyHat(model, Hw, W)

        Jacobi_X[i,:,:].assign( H )
        Jacobi_W[i,:,:].assign( Hw )

        el                              = y_pred - tf.linalg.matvec(H, m_pred) 
        eta1                            = eta0
        for j in range(1,Nstep+1): 
            eta1_move, eta_move         = EDH_flow_dynamics(Np, ndims, Rates[j], Steps[j], I, eta, eta1, P_pred, H, R, el, y[i,:], u)  
            eta.assign_add(eta_move)
            eta1.assign_add(eta1_move)
            
        lp                              = EDH_flow_lp(Np, eta0, eta1, x_prev, y[i,:], P_pred, y_pred, R, u)     
        w_pred                          = compute_weights(w_prev, lp)
        w_norm                          = normalize_weights(w_pred)        
        ness                            = compute_ESS(w_norm)
        ESS[i].assign(ness)
        Weights[i,:].assign(w_norm)   
             
        if ness < NT: 
            xbar, wbar  = multinomial_resample(Np, eta1, w_norm)
            x_filt      = compute_posterior(wbar, xbar)
            x_prev      = xbar
        else: 
            x_filt      = compute_posterior(w_norm, eta1)
            x_prev      = eta1
        
        X_filtered[i,:].assign(x_filt) 
        
        if method == "UKF":
            K                           = UKF_Gain(Rcross, R, u)
            _, P_filt                   = UKF_Filter(m_pred, P_pred, R, y[i,:], y_pred, K)
        if method == "EKF":    
            K                           = EKF_Gain(P_pred, H, Hw, W, u)
            _, P_filt                   = EKF_Filter(m_pred, P_pred, y[i,:], y_pred, H, K)
        P_prev      = P_filt
        
    return X_filtered, ESS, Weights, Jacobi_X, Jacobi_W


###############################
# Particle Flow Filter - LEDH # 
###############################



def LEDH_linearize_EKF(N, n, model, I1, xprev, Pprev, A, B, V, W, muy, U): 
    """Predict the pseudo particles, eta and eta0, by EKF using the previous state and its associated particles, xhat and xprev."""
    
    eta0            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    eta             = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    m               = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    P               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))

    y               = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    H               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    Hw              = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    Cy              = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    err             = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    
    for i in range(N): 

        mi_pred, Pi_pred        = EKF_Predict(xprev[i,:], Pprev[i,:,:], A, V) 
        
        eta[i,:].assign(mi_pred)
        eta0[i,:].assign( norm_rvs(n, mi_pred, Pi_pred + U) )
        m[i,:].assign(mi_pred)
        P[i,:,:].assign(Pi_pred)

        yi_pred     = measurements_pred(model, n, muy, B, eta[i,:], W, U)
        y[i,:].assign(yi_pred)
        
        Jxi, Jwi    = measurements_Jacobi(model, I1, eta[i,:], yi_pred, B)
        H[i,:,:].assign( Jxi )
        Hw[i,:,:].assign( Jwi )

        Cyi         = measurements_covyHat(model, Jwi, W)
        Cy[i,:,:].assign( Cyi )
        err[i,:].assign( yi_pred - tf.linalg.matvec(Jxi, eta[i,:]) )
        

    return eta, eta0, m, P, y, H, Hw, Cy, err

def LEDH_update_EKF(N, n, m0, P0, y, yhat, Hx, Hw, W, U):
    """Compute the Extended Kalman Gain and return the updated covariance matricies of the particles."""
    P               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    for i in range(N): 
        K           = EKF_Gain(P0[i,:,:], Hx[i,:,:], Hw[i,:,:], W, U)
        _, Pi       = EKF_Filter(m0[i,:], P0[i,:,:], y, yhat[i,:], Hx[i,:,:], K)
        P[i,:,:].assign(Pi)
    return P

def LEDH_linearize_UKF(N, n, model, I1, xprev, Pprev, A, B, V, W, wm, wc, wi, L, U):
    """Predict the pseudo particles, eta and eta0, by UKF using the previous state and its associated particles, xhat and xprev."""
    
    eta0            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    eta             = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    m               = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    P               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))

    y               = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    H               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    Hw              = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    Cy              = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    CyCross         = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    err             = tf.Variable(tf.zeros((N,n), dtype=tf.float64))

    x_pred0         = tf.Variable(tf.zeros((n*2,), dtype=tf.float64))
    P_pred0         = tf.Variable(tf.zeros((n*2,n*2), dtype=tf.float64))
    P_pred0[n:n*2,n:n*2].assign(W) 
    
    for i in range(N): 
        
        Xprev_sp    = SigmaPoints(n, xprev[i,:], Pprev[i,:,:], L)
        X_sp        = Xprev_sp @ tf.transpose(A) 

        mi_pred     = UKF_Predict_mean(wm, wi, X_sp) 
        Pi_pred     = UKF_Predict_cov(n, wc, wi, X_sp, mi_pred, U, Cov=V)  
        
        eta[i,:].assign(mi_pred)
        eta0[i,:].assign( norm_rvs(n, mi_pred, Pi_pred + U) )        
        m[i,:].assign(mi_pred)
        P[i,:,:].assign(Pi_pred)

        if model == "SV" :
            x_pred0[:n].assign(mi_pred)
            P_pred0[0:n,0:n].assign(Pi_pred)
        if model == "LG": 
            x_pred0 = mi_pred 
            P_pred0 = Pi_pred
        
        yi_pred, W_pred, Rcross = UKF_Predict(model, n, x_pred0, P_pred0, wm, wc, wi, L, B, W, U)
        Jxi, Jwi    = measurements_Jacobi(model, I1, mi_pred, yi_pred, B)

        y[i,:].assign(yi_pred)
        Cy[i,:,:].assign(W_pred)
        CyCross[i,:,:].assign(Rcross)
        H[i,:,:].assign( Jxi )
        Hw[i,:,:].assign( Jwi )
        err[i,:].assign( yi_pred - tf.linalg.matvec(Jxi, mi_pred) )        
    
    return eta, eta0, m, P, y, H, Hw, Cy, CyCross, err 


def LEDH_update_UKF(N, n, m0, P0, y, yhat, W_pred, C_pred, U):
    """Compute the Unscented Kalman Gain and return the updated covariance matricies of the particles."""
    P               = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64))
    for i in range(N): 
        K           = UKF_Gain(C_pred[i,:,:], W_pred[i,:,:], U)
        _, Pi       = UKF_Filter(m0[i,:], P0[i,:,:], W_pred[i,:,:], y, yhat[i,:], K)
        P[i,:,:].assign(Pi)
    return P

def LEDH_flow_dynamics(N, n, Lamb, epsilon, I, eta, eta0, Pi, Hi, Ri, err, y, U):
    """Compute and return the flow dynamics of the pseudo particles for migration."""
    move0           = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    move            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    prod            = tf.Variable(tf.zeros((N,), dtype=tf.float64))    
    for i in range(N):                 
        Ai          = Li17eq10(Lamb, Hi[i,:,:], Pi[i,:,:], Ri[i,:,:], U)
        bi          = Li17eq11(I, Lamb, Ai, Hi[i,:,:], Pi[i,:,:], Ri[i,:,:], y, err[i,:], eta[i,:], U)
        move0[i,:].assign( epsilon * (tf.linalg.matvec(Ai, eta0[i,:]) + bi) )
        move[i,:].assign( epsilon * (tf.linalg.matvec(Ai, eta[i,:]) + bi) )
        prod[i].assign( tf.math.abs( tf.linalg.det(I + epsilon * Ai) ) )
    return move0, move, prod

def LEDH_flow_lp(N, eta0, theta, eta1, xprev, y, SigmaX, muy, SigmaY, U):
    """Compute and return the log posterior of the migrated pseudo particles."""
    Lp              = tf.Variable(tf.zeros((N,), dtype=tf.float64)) 
    for i in range(N):  
        Lp[i].assign( tf.math.log(theta[i]) + LogLikelihood(y, muy[i,:], SigmaY[i,:,:], U) + LogTarget(eta1[i,:], xprev[i,:], SigmaX[i,:,:]) - LogImportance(eta0[i,:], xprev[i,:], SigmaX[i,:,:]) )  
    return Lp

def LEDH(y, model=None, A=None, B=None, V=None, W=None, N=None, Nstep=None, mu0=None, Sigma0=None, muy=None, method=None, stepsize=None, stochastic=False, mc=None, Q=None):
    """
    Compute the estimated states using the LEDH given the measurements. 

    Keyword args:
    ------------- 
    y : tf.Variable of float64 with dimension (nTimes,ndims). The observed measurements. 
    model: string, optional. The name of the measurement model. Defaults to linear Gaussian "LG" if not provided.A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    A : tf.Tensor of float64 with shape (ndims,ndims), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    B : tf.Tensor of float64 with shape (ndims,ndims), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (ndims,ndims), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims), optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    N : int32, optional. Number of particles. Defaults to 1000 if not provided.
    Nstep : int32, optional. Number of steps in the psuedo time interval [0,1]. Defaults to 30 if not provided.
    mu0 : tf.Tensor of float64 with shape (ndims,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (ndims,ndims). The prior covariance for initial state. Defaults to predefined covariance using V and A if not provided.
    muy : tf.Tensor of float64 with shape (ndims,), optioanl. The scalar means of the measurements. Defaults to zeros if not provided.
    method : str, optional. The linearization method. Defaults to "EKF" if not provided.  
    stepsize : float64, optional. The first stepsize in the psuedo time interval [0,1]. Defaults to 1e-3 if not provided. 
    
    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,ndims). The filtered states given by the LEDH. 
    ESS : tf.Variable of float64 with dimension (nTimes,). The effective sample sizes. 
    Weights : tf.Variable of float64 with dmension (nTimes,N). The weights of particles. 
    JacobiX : tf.Variable of float64 with dimension (nTimes,N,ndims,ndims). The pseudo Jacobian matrix with respect to the state. 
    JacobiW : tf.Variable of float64 with dimension (nTimes,N,ndims,ndims). The pseudo Jacobian matrix with respect to the noise. 
    """
    
    nTimes, ndims   = y.shape 
    model           = "LG" if model is None else model
    if model == "sensor" and ndims != 2:
        raise ValueError("The state space dimension must be 2 for the location sensoring model.")
    
    if model == "SV" and A is None : 
        A           = tf.eye(ndims, dtype=tf.float64) * 0.5  
    if model == "SV" and A is not None :
        if tf.reduce_max(A) > 1.0:
            raise ValueError("The matrix A out of range [-1,1].")
        if tf.reduce_min(A) < -1.0:
            raise ValueError("The matrix A out of range [-1,1].")
    if model != "SV" and A is None : 
        A           = tf.eye(ndims, dtype=tf.float64) 
    
    B               = tf.eye(ndims, dtype=tf.float64) if B is None else B
    V               = tf.eye(ndims, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W

    if model == "sensor" and mu0 is None:
        mu0         = tf.constant([3.0,5.0], dtype=tf.float64) 
    else:
        mu0         = tf.zeros((ndims,), dtype=tf.float64)   
        
    if model == "SV" and Sigma0 is None :
        Sigma0      = V @ tf.linalg.inv(tf.eye(ndims, dtype=tf.float64) - A @ A)  
    if model != "SV" and Sigma0 is None: 
        Sigma0      = V

    muy             = tf.zeros((ndims,), dtype=tf.float64) if muy is None else muy
    u               = tf.eye(ndims, dtype=tf.float64) * 1e-9
    I               = tf.eye(ndims, dtype=tf.float64)
    I1              = tf.ones((ndims,), dtype=tf.float64)
    weight0_m, weight0_c, weighti, L = SigmaWeights(ndims)

    N               = 100 if N is None else N
    Np              = N
    NT              = N/2

    method          = "EKF" if method is None else method     
    stepsize        = 1e-3 if stepsize is None else stepsize     
    Nstep           = 30 if Nstep is None else Nstep

    if stochastic: 
        Rates       = tf.constant(tf.linspace(0.0, 1.0, Nstep + 1).numpy(), dtype=tf.float64)
        mc          = 0.045 if mc is None else mc
        Q           = tf.eye(ndims, dtype=tf.float64) if Q is None else Q
        q           = tf.linalg.cholesky(Q)
        w0          = tf.zeros((ndims,), dtype=tf.float64)
        I           = tf.eye(ndims, dtype=tf.float64)
    else:
        Steps       = tf.constant([stepsize * (1.2*i) for i in range(Nstep+1)], dtype=tf.float64)
        Rates       = tf.math.cumsum(Steps) 

    JacobiX         = tf.Variable(tf.zeros((nTimes, Np, ndims, ndims), dtype=tf.float64))
    JacobiW         = tf.Variable(tf.zeros((nTimes, Np, ndims, ndims), dtype=tf.float64))
    Weights         = tf.Variable(tf.zeros((nTimes, Np), dtype=tf.float64))
    ESS             = tf.Variable(tf.zeros((nTimes,), dtype=tf.float64))
    X_filtered      = tf.Variable(tf.zeros((nTimes, ndims), dtype=tf.float64))

    P0              = A @ Sigma0 @ tf.transpose(A) + V
    P_prev          = tf.Variable(tf.zeros((Np,ndims,ndims), dtype=tf.float64))
    for i in range(Np):
        P_prev[i,:,:].assign(P0)

    x_prev          = initiate_particles(Np, ndims, mu0, P0)
    w_prev          = tf.Variable(tf.ones((N,), dtype=tf.float64) / N) 

    for i in range(nTimes): 

        if method == "UKF":        
            eta, eta0, m_pred, P_pred, y_pred, H, Hiw, R, Rcross, el = LEDH_linearize_UKF(Np, ndims, model, I1, x_prev, P_prev, A, B, V, W, weight0_m, weight0_c, weighti, L, u)
        if method == "EKF":            
            eta, eta0, m_pred, P_pred, y_pred, H, Hiw, R, el = LEDH_linearize_EKF(Np, ndims, model, I1, x_prev, P_prev, A, B, V, W, muy, u)
        if stochastic: 
            HessiansPrios, HessiansLike, JacobiLike = LEDH_SDE_Hessians(Np, P_pred, y[i,:], y_pred, R, u)
        
        JacobiX[i,:,:,:].assign(H)
        JacobiW[i,:,:,:].assign(Hiw)

        eta1        = eta0
        theta       = tf.Variable(tf.ones((Np,), dtype=tf.float64))
        for j in range(1,Nstep+1): 

            if stochastic: 
                dL  = Rates[j] - Rates[j-1]
                eta1_move, theta_prod = LEDH_SDE_flow_dynamics(Np, ndims, Rates[j], dL, eta0, eta1, x_prev, P_pred, HessiansPrios, HessiansLike, JacobiLike, mc, w0, I, Q, q, u)
                theta2 = theta * theta_prod
                eta1.assign_add(eta1_move)
                theta.assign(theta2)
            else:
                eta1_move, eta_move, theta_prod = LEDH_flow_dynamics(Np, ndims, Rates[j], Steps[j], I, eta, eta1, P_pred, H, R, el, y[i,:], u)                   
                theta2 = theta * theta_prod
                eta.assign_add(eta_move)
                eta1.assign_add(eta1_move)
                theta.assign(theta2)
            
        lp          = LEDH_flow_lp(Np, eta0, theta, eta1, x_prev, y[i,:], P_pred, y_pred, R, u)       
        w_pred      = compute_weights(w_prev, lp)
        w_norm      = normalize_weights(w_pred)        
        ness        = compute_ESS(w_norm)

        ESS[i].assign(ness)
        Weights[i,:].assign(w_norm)   
             
        if ness < NT: 
            xbar, wbar  = multinomial_resample(Np, eta1, w_norm)
            x_filt      = compute_posterior(wbar, xbar)
            x_prev      = xbar
        else: 
            x_filt      = compute_posterior(w_norm, eta1)
            x_prev      = eta1

        X_filtered[i,:].assign(x_filt) 
        
        if method == "UKF":
            P_filt  = LEDH_update_UKF(Np, ndims, m_pred, P_pred, y[i,:], y_pred, R, Rcross, u) 
        if method == "EKF":    
            P_filt  = LEDH_update_EKF(Np, ndims, m_pred, P_pred, y[i,:], y_pred, H, Hiw, W, u)
        
        P_prev          = P_filt
        
    return X_filtered, ESS, Weights, JacobiX, JacobiW


#####################################
# Particle Flow Filter - Kernel PFF # 
#####################################

def Hu21eq13(model, y, ypred, Jx, Jw, W, U):
    R               = measurements_covyHat(model, Jw, W)
    Rinv            = tf.linalg.inv(R + U)  
    return tf.linalg.matvec( tf.transpose(Jx) @ Rinv, y - ypred)  

def Hu21eq15(xpred, x0, Sigma0, U):
    return tf.linalg.matvec( tf.linalg.inv(Sigma0 + U), xpred - x0)

def KPFF_LP(N, nx, n, model, I, x, y, muy, B, W, mu0, Sigma0, U, Uy):
    JxC             = tf.Variable(tf.zeros((N,n,nx), dtype=tf.float64)) 
    JwC             = tf.Variable(tf.zeros((N,n,n), dtype=tf.float64)) 
    LP              = tf.Variable(tf.zeros((N,nx), dtype=tf.float64))
    for i in range(N):
        
        yi_pred     = measurements_pred(model, n, muy, B, x[i,:], W, Uy)      
        Hx, Hw      = measurements_Jacobi(model, I, x[i,:], yi_pred, B) 
    
        Hxj         = tf.reshape(tf.linalg.diag_part(Hx), [n,1])
        Jx          = tf.tile(tf.reshape(Hxj,[n,1]), [1,nx]) 
                       
        lpi         = Hu21eq13(model, y, yi_pred, Jx, Hw, W, Uy) - Hu21eq15(x[i,:], mu0, Sigma0, U)
        
        LP[i,:].assign(lpi)
        JxC[i,:,:].assign(Jx)
        JwC[i,:,:].assign(Hw)
        
    return LP, JxC, JwC

def KPFF_RKHS(N, n, x, Lp, Sigma0):
    In              = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    for i in range(n): 
        K, Kc       = SE_Cov_div(N, x[:,i], length=Sigma0[i,i])
        for j in range(N): 
            In[j,i].assign( tf.reduce_sum(1/N * ( Lp[j,i] * K[j,:] + Kc[j,:] * K[j,:] )) )
    return In

def KPFF_flow(N, n, epsilon, integral, Sigma0):
    xadd            = tf.Variable(tf.zeros((N,n), dtype=tf.float64))
    for i in range(N):
        field       = tf.linalg.matvec( Sigma0, integral[i,:] )
        xadd[i,:].assign( epsilon * field )
    return xadd 


def KernelPFF(y, Nx, model=None, A=None, B=None, V=None, W=None, N=None, Nstep=None, mu0=None, Sigma0=None, muy=None, method=None, stepsize=None):
    """
    Compute the estimated states using the Kernel PFF given the measurements. 

    Keyword args:
    -------------
    y : tf.Variable of float64 with dimension (nTimes,ndims). The observed measurements. 
    Nx : int32. The dimension of the state. 
    A : tf.Tensor of float64 with shape (Nx,Nx), optional. The transition matrix. Defaults to diagonal matrix of 0.5 if not provided.
    B : tf.Tensor of float64 with shape (ndims,Nx), optional. The output matrix. Defaults to identity matrix if not provided.
    V : tf.Tensor of float64 with shape (Nx,Nx), optional. The system noise matrix. Defaults to identity matrix if not provided.
    W : tf.Tensor of float64 with shape (ndims,ndims)., optional. The measurement noise matrix. Defaults to identity matrix if not provided.
    N : int32, optional. Number of particles. Defaults to 1000 if not provided.
    Nstep : int32, optional. Number of steps in the psuedo time interval [0,1]. Defaults to 30 if not provided.
    mu0 : tf.Tensor of float64 with shape (Nx,), optioanl. The prior mean for initial state. Defaults to zeros if not provided.
    Sigma0 : tf.Tensor of float64 with shape (Nx,Nx). The prior covariance for initial state. Defaults to predefined covariance using V and A if not provided.
    muy : tf.Tensor of float64 with shape (ndims,), optioanl. The expectation of the measurements. Defaults to zeros if not provided.
    method : str, optional. The linearization method. Defaults to "kernel" if not provided.
    stepsize : float64, optional. The stepsize in the psuedo time interval [0,1]. Defaults to 1e-3 if not provided. 
    
    Returns:
    --------
    X_filtered : tf.Variable of float64 with dimension (nTimes,Nx). The filtered states given by the Kernel PFF.
    JacobiX : tf.Variable of float64 with dimension (nTimes,Nstep,N,ndims,Nx). The pseudo Jacobian matrix with respect to the state. 
    JacobiW : tf.Variable of float64 with dimension (nTimes,Nstep,N,ndims,ndims). The pseudo Jacobian matrix with respect to the noise. 
    X_part : tf.Variable of float64 with dimension (nTimes,N,Nx). The prior particles given by the Kernel PFF.
    X_part2 : tf.Variable of float64 with dimension (nTimes,N,Nx). The posterior particles given by the Kernel PFF.
    """
    
    nTimes, ndims   = y.shape 
    model           = "LG" if model is None else model
    
    if model == "SV" and A is None : 
        A           = tf.eye(Nx, dtype=tf.float64) * 0.5 if A is None else A
    if model == "SV" and A is not None :
        if tf.reduce_max(A) > 1.0:
            raise ValueError("The matrix A out of range [-1,1].")
        if tf.reduce_min(A) < -1.0:
            raise ValueError("The matrix A out of range [-1,1].")
    if model != "SV" and A is None : 
        A           = tf.eye(Nx, dtype=tf.float64) 

    if ndims != Nx and B is None:
        B           = tf.ones((ndims, Nx), dtype=tf.float64)
    if ndims == Nx and B is None: 
        B           = tf.eye(ndims, dtype=tf.float64) 

    V               = tf.eye(Nx, dtype=tf.float64) if V is None else V 
    W               = tf.eye(ndims, dtype=tf.float64) if W is None else W

    mu0             = tf.zeros((Nx,), dtype=tf.float64) if mu0 is None else mu0
    if model == "SV" and Sigma0 is None :
        Sigma0      = V @ tf.linalg.inv(tf.eye(Nx, dtype=tf.float64) - A @ A)  
    if model != "SV" and Sigma0 is None : 
        Sigma0      = V  
    muy             = tf.zeros((ndims,), dtype=tf.float64) if muy is None else muy

    N               = 1000 if N is None else N
    Np              = N
    
    method          = "kernel" if method is None else method 
    stepsize        = 1e-3 if stepsize is None else stepsize     
    Nstep           = 30 if Nstep is None else Nstep
    Rates           = [stepsize] + [stepsize * (1.2*i) for i in range(1,Nstep)]
    
    u               = tf.eye(Nx, dtype=tf.float64) * 1e-9
    uy              = tf.eye(ndims, dtype=tf.float64) * 1e-9
    I1              = tf.ones((ndims,), dtype=tf.float64)

    x_hat           = mu0
    
    X_filtered      = tf.Variable(tf.zeros((nTimes, Nx), dtype=tf.float64))   
    X_part          = tf.Variable(tf.zeros((nTimes, N, Nx), dtype=tf.float64))
    X_part2         = tf.Variable(tf.zeros((nTimes, N, Nx), dtype=tf.float64))
    JacobiX         = tf.Variable(tf.zeros((nTimes, Nstep, Np, ndims, Nx), dtype=tf.float64))  
    JacobiW         = tf.Variable(tf.zeros((nTimes, Nstep, Np, ndims, ndims), dtype=tf.float64))  
    
    for i in range(nTimes): 
    
        x_prev      = initiate_particles(Np, Nx, x_hat, Sigma0)
        X_part[i,:,:].assign(x_prev)

        for j in range(Nstep): 
            
            grad, Jx, Jw = KPFF_LP(Np, Nx, ndims, model, I1, x_prev, y[i,:], muy, B, W, x_hat, Sigma0, u, uy)
            
            if method == "kernel":
                II  = KPFF_RKHS(Np, Nx, x_prev, grad, Sigma0)
            if method == "scalar":
                II  = grad / Np

            x_move  = KPFF_flow(Np, Nx, Rates[j], II, Sigma0)
            x_prev.assign_add(x_move) 
            
            JacobiX[i,j,:,:,:].assign(Jx)
            JacobiW[i,j,:,:,:].assign(Jw)

        x_hat       = tf.Variable( tf.reduce_mean(x_prev, axis=0) )   

        X_part2[i,:,:].assign(x_prev)         
        X_filtered[i,:].assign(x_hat)

    return X_filtered, JacobiX, JacobiW, X_part, X_part2